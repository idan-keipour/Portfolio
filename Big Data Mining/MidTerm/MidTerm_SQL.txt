## MidTerm 52002 2022

# Student IDs: 
ID1: 314696972
ID2: 315355537

""" Query 1: """

SELECT id, title, tags, score, view_count, answer_count FROM `bigquery-public-data.stackoverflow.stackoverflow_posts` WHERE tags like '%java%' order by score desc LIMIT 5;

""" Query 1 Output (Json): """

{  "id": "11227809",  "title": "Why is processing a sorted array faster than an unsorted array?",  "tags": "java|c++|performance|optimization|branch-prediction",  "score": "14772",  "view_count": "805490",  "answer_count": "13"}
{  "id": "111102",  "title": "How do JavaScript closures work?",  "tags": "javascript|scope|closures",  "score": "5969",  "view_count": "810141",  "answer_count": "79"}
{  "id": "503093",  "title": "How can I make a page redirect using jQuery?",  "tags": "javascript|jquery|redirect",  "score": "5185",  "view_count": "2946923",  "answer_count": "55"}
{  "id": "1789945",  "title": "How can I check if one string contains another substring?",  "tags": "javascript|string|string-matching",  "score": "4728",  "view_count": "3036124",  "answer_count": "38"}
{  "id": "1335851",  "title": "What does use strict do in JavaScript and what is the reasoning behind it?",  "tags": "javascript|syntax|jslint|use-strict",  "score": "4646",  "view_count": "640354",  "answer_count": "19"}

""" Query 2: """

SELECT count(id) as Number_Of_Questions, 
  countif(answer_count>=1) as Answered_Questions, 
    avg(answer_count) as Average_Of_Answers, 
      avg(view_count) as Average_Of_Views, 
        avg(score) as Average_Of_Score FROM `bigquery-public-data.stackoverflow.stackoverflow_posts` WHERE tags like '%java%';

""" Query 2 Output (Json): """

{  "Number_Of_Questions": "2261370",  "Answered_Questions": "1985846",  "Average_Of_Answers": "1.7112793179706631",  "Average_Of_Views": "1775.549818716009",  "Average_Of_Score": "1.6962328146212247"}

""" Query 3: """

SELECT count(id) as Number_Of_Questions, 
  countif(answer_count>=1) as Answered_Questions,
     avg(answer_count) as Average_Of_Answers,
       avg(view_count) as Average_Of_Views,
        avg(score) as Average_Of_Score, EXTRACT(HOUR FROM creation_date) as Hour_In_Day FROM `bigquery-public-data.stackoverflow.stackoverflow_posts` WHERE tags like '%java%' GROUP BY Hour_In_Day;

""" Query 3 Output (Json): """
{  "Number_Of_Questions": "115586",  "Answered_Questions": "100668",  "Average_Of_Answers": "1.7060543664457637",  "Average_Of_Views": "1717.2140657173015",  "Average_Of_Score": "1.6070285328673026",  "Hour_In_Day": "11"}
{  "Number_Of_Questions": "130692",  "Answered_Questions": "114186",  "Average_Of_Answers": "1.7136397025066563",  "Average_Of_Views": "1800.0772809353293",  "Average_Of_Score": "1.7869188626694823",  "Hour_In_Day": "14"}
{  "Number_Of_Questions": "91791",  "Answered_Questions": "79991",  "Average_Of_Answers": "1.7149829503981864",  "Average_Of_Views": "1597.4744582802246",  "Average_Of_Score": "1.4129598762405908",  "Hour_In_Day": "7"}
{  "Number_Of_Questions": "53320",  "Answered_Questions": "47404",  "Average_Of_Answers": "1.688203300825206",  "Average_Of_Views": "1717.0525693923485",  "Average_Of_Score": "1.584921230307577",  "Hour_In_Day": "2"}
{  "Number_Of_Questions": "53513",  "Answered_Questions": "47692",  "Average_Of_Answers": "1.6892343916431523",  "Average_Of_Views": "1810.5012053145949",  "Average_Of_Score": "1.6536542522377746",  "Hour_In_Day": "1"}
{  "Number_Of_Questions": "121362",  "Answered_Questions": "106327",  "Average_Of_Answers": "1.6952176134210044",  "Average_Of_Views": "1776.8717143751751",  "Average_Of_Score": "1.7846360475272331",  "Hour_In_Day": "16"}
{  "Number_Of_Questions": "130059",  "Answered_Questions": "113778",  "Average_Of_Answers": "1.7015431458030588",  "Average_Of_Views": "1770.3799275713322",  "Average_Of_Score": "1.6997285847192429",  "Hour_In_Day": "15"}
{  "Number_Of_Questions": "119663",  "Answered_Questions": "104159",  "Average_Of_Answers": "1.6977929685867812",  "Average_Of_Views": "1744.9034204390662",  "Average_Of_Score": "1.6016730317642047",  "Hour_In_Day": "10"}
{  "Number_Of_Questions": "82049",  "Answered_Questions": "71619",  "Average_Of_Answers": "1.7506002510694831",  "Average_Of_Views": "1753.3142512401118",  "Average_Of_Score": "1.5218345135224081",  "Hour_In_Day": "6"}
{  "Number_Of_Questions": "79602",  "Answered_Questions": "70631",  "Average_Of_Answers": "1.6916409135448862",  "Average_Of_Views": "1811.1658375417705",  "Average_Of_Score": "1.820456772442903",  "Hour_In_Day": "22"}
{  "Number_Of_Questions": "110437",  "Answered_Questions": "97317",  "Average_Of_Answers": "1.7123065639233239",  "Average_Of_Views": "1865.9035015438662",  "Average_Of_Score": "1.7617465161132591",  "Hour_In_Day": "18"}
{  "Number_Of_Questions": "57921",  "Answered_Questions": "51478",  "Average_Of_Answers": "1.6778197890229793",  "Average_Of_Views": "1851.2699884325204",  "Average_Of_Score": "1.8611211823000289",  "Hour_In_Day": "0"}
{  "Number_Of_Questions": "101799",  "Answered_Questions": "90081",  "Average_Of_Answers": "1.7228165306142498",  "Average_Of_Views": "1857.8552048644876",  "Average_Of_Score": "1.8643110443128135",  "Hour_In_Day": "20"}
{  "Number_Of_Questions": "57802",  "Answered_Questions": "51391",  "Average_Of_Answers": "1.7701290612781564",  "Average_Of_Views": "1775.9918514930278",  "Average_Of_Score": "1.6841458773052838",  "Hour_In_Day": "4"}
{  "Number_Of_Questions": "112751",  "Answered_Questions": "99008",  "Average_Of_Answers": "1.6963219838404975",  "Average_Of_Views": "1763.1983219661013",  "Average_Of_Score": "1.6796569431756703",  "Hour_In_Day": "17"}
{  "Number_Of_Questions": "97379",  "Answered_Questions": "84961",  "Average_Of_Answers": "1.7177420182996332",  "Average_Of_Views": "1735.1795561671402",  "Average_Of_Score": "1.7275901375039784",  "Hour_In_Day": "8"}
{  "Number_Of_Questions": "92774",  "Answered_Questions": "82035",  "Average_Of_Answers": "1.7061568974066013",  "Average_Of_Views": "1799.0180330696105",  "Average_Of_Score": "1.747181322353246",  "Hour_In_Day": "21"}
{  "Number_Of_Questions": "124577",  "Answered_Questions": "108783",  "Average_Of_Answers": "1.7210881623413636",  "Average_Of_Views": "1791.3661510551706",  "Average_Of_Score": "1.8586898063045347",  "Hour_In_Day": "13"}
{  "Number_Of_Questions": "116379",  "Answered_Questions": "101303",  "Average_Of_Answers": "1.7106178949810533",  "Average_Of_Views": "1683.012888923259",  "Average_Of_Score": "1.5586317119067874",  "Hour_In_Day": "9"}
{  "Number_Of_Questions": "106013",  "Answered_Questions": "93568",  "Average_Of_Answers": "1.7153273655117776",  "Average_Of_Views": "1878.6541178912028",  "Average_Of_Score": "1.8262382915302839",  "Hour_In_Day": "19"}
{  "Number_Of_Questions": "68117",  "Answered_Questions": "59966",  "Average_Of_Answers": "1.7616272241470439",  "Average_Of_Views": "1826.3170327089092",  "Average_Of_Score": "1.5128088436073226",  "Hour_In_Day": "5"}
{  "Number_Of_Questions": "117642",  "Answered_Questions": "102739",  "Average_Of_Answers": "1.7269597592696488",  "Average_Of_Views": "1725.8189677156117",  "Average_Of_Score": "1.6033219428435415",  "Hour_In_Day": "12"}
{  "Number_Of_Questions": "53992",  "Answered_Questions": "47888",  "Average_Of_Answers": "1.6994739961475773",  "Average_Of_Views": "1802.2751889168769",  "Average_Of_Score": "1.6675433397540373",  "Hour_In_Day": "3"}
{  "Number_Of_Questions": "66150",  "Answered_Questions": "58873",  "Average_Of_Answers": "1.6825850340136057",  "Average_Of_Views": "1828.4070445956163",  "Average_Of_Score": "1.7731065759637188",  "Hour_In_Day": "23"}

""" Query 3  Answer:  """

As you can see that at two o'clock at night the most questions were posted and the fewest questions that were posted on the site was at one o'clock at night.
If we look across the number of answers we received for the questions, we found that the least was received at one in the night and the most at two in the afternoon. The quality of the questions can be seen by the average score. It is obtained that at two at night the lowest compared to one in the afternoon, which is the highest. This makes sense according to the number of views for the questions. At 11 the highest number of views is obtained.

""" Query 4: """

(select about_me, website_url, reputation,location, display_name from `bigquery-public-data.stackoverflow.users`  where (lower(location) like '%damascus%') and (lower(about_me) like '%python%') order by reputation desc);
(select about_me, website_url, reputation,location, display_name from `bigquery-public-data.stackoverflow.users` where (lower(location) like '%syria%') and (lower(about_me) like '%python%') order by reputation desc limit 1);

""" Query 4 Output (Json): """

{  "about_me": "\u003cp\u003eAI student love programming\nknow many languages like c/c++ c# java python lisp prolog \nAsp.net\nhave Participated in ACM -SCPC and ACM -SyuCPC twice and DUCPC \u003c/p\u003e",  "website_url": null,  "reputation": "89",  "location": "Damascus, Syria",  "display_name": "DaRkViRuS"}
{  "about_me": "\u003cp\u003ei Am AI Engineer Student at Damascus University\nI have worked with programming language such as c,c++,Java,python\nI have some work in Android Development Using Android Studio and Java language\ni worked on a game using unity and C# scripts\ni developed two desktop apps using javafx library\u003c/p\u003e",  "website_url": null,  "reputation": "41",  "location": "Damascus, Syria",  "display_name": "Mohammad Abdulhai"}
{  "about_me": "\u003cp\u003eHi, I am Fahd Soliman. I have good experience in software engineering. I adore C# and love it. I love learning new technologies, so I also learned Python and Java.\u003c/p\u003e",  "website_url": "https://portfoliofahd.herokuapp.com/",  "reputation": "1",  "location": "Damascus, Syria",  "display_name": "Fahd Soliman"}

""" Query 5: """

SELECT date_diff(CAST(current_date AS DATE),CAST(creation_date AS DATE),YEAR) AS Seniority ,
 avg(reputation) AS Reputation_AVG,
  FROM `bigquery-public-data.stackoverflow.users` GROUP BY Seniority ORDER BY Seniority;

""" Query 5 Output (Json): """

{  "Seniority": "0",  "Reputation_AVG": "1.7575046088559687"}
{  "Seniority": "1",  "Reputation_AVG": "3.2866833680432896"}
{  "Seniority": "2",  "Reputation_AVG": "7.3805931935005091"}
{  "Seniority": "3",  "Reputation_AVG": "12.628004504646244"}
{  "Seniority": "4",  "Reputation_AVG": "19.49546594131472"}
{  "Seniority": "5",  "Reputation_AVG": "27.238851152058327"}
{  "Seniority": "6",  "Reputation_AVG": "44.700320709601044"}
{  "Seniority": "7",  "Reputation_AVG": "72.023086779321517"}
{  "Seniority": "8",  "Reputation_AVG": "97.804613078763566"}
{  "Seniority": "9",  "Reputation_AVG": "153.99900895593646"}
{  "Seniority": "10",  "Reputation_AVG": "335.55857675849467"}
{  "Seniority": "11",  "Reputation_AVG": "719.58364561027884"}
{  "Seniority": "12",  "Reputation_AVG": "1215.6084915370832"}
{  "Seniority": "13",  "Reputation_AVG": "3425.7987535904795"}
{  "Seniority": "14",  "Reputation_AVG": "9133.018900184843"}

""" Query 5  Answer:  """

It can be deduced from what we have received that he is indeed right, since we have received that there is a positive correlation between seniority and average reputation. That is, as seniority increases, reputation increases.

""" Query 6: """

select case when a.profile_image_url is not null then  "yes" else "no" end as Profile_Image_yesno,
  countif(b.answer_count>0)/count(b.id) as Percentage_Response, avg(reputation) as Average_Reputation
  from `bigquery-public-data.stackoverflow.users` as a join `bigquery-public-data.stackoverflow.posts_questions` as b on a.id = b.owner_user_id
  group by case when a.profile_image_url is not null then "yes" else "no" end;

""" Query 6 Output (Json): """

{  "Profile_Image_yesno": "yes",  "Percentage_Response": "0.82992580485492773",  "Average_Reputation": "2446.1805356028244"}
{  "Profile_Image_yesno": "no",  "Percentage_Response": "0.90257053951284549",  "Average_Reputation": "6748.4738337683066"}

""" Query 6  Answer:  """

Surprisingly it was found that for posts without an image more responses were received compared to the posts with an image of the user.
 It should be noted that the response rate is higher in pen than the unanswered percentage.

""" Query 7: """

select questions.id, replace(questions.title,",",";"), replace(questions.tags,",",";"), questions.answer_count, 
  questions.score as question_scoer, questions.creation_date as questions_creation_date,
  answers.score as answers_score, answers.creation_date as answers_creation_date,
  replace(replace(questions.body,chr(10)," "),",",";") as questions_body ,replace(replace(answers.body,chr(10)," "),",",";") as answers_body  #to replace  '\n'
  from `bigquery-public-data.stackoverflow.posts_questions` as questions
  join  `bigquery-public-data.stackoverflow.posts_answers` as answers
  on answers.parent_id= questions.id
  where questions.title like '%numpy%';

""" Query 7 Output (Json): """

{  "id": "643699",  "f0_": "How can I use numpy.correlate to do autocorrelation?",  "f1_": "python|math|numpy|numerical-methods",  "answer_count": "13",  "question_scoer": "125",  "questions_creation_date": "2009-03-13T17:07:53.470Z",  "answers_score": "0",  "answers_creation_date": "2015-02-01T21:17:42.833Z",  "questions_body": "\u003cp\u003eI need to do auto-correlation of a set of numbers; which as I understand it is just the correlation of the set with itself. \u003c/p\u003e  \u003cp\u003eI\u0027ve tried it using numpy\u0027s correlate function; but I don\u0027t believe the result; as it almost always gives a vector where the first number is \u003cem\u003enot\u003c/em\u003e the largest; as it ought to be.\u003c/p\u003e  \u003cp\u003eSo; this question is really two questions:\u003c/p\u003e  \u003col\u003e \u003cli\u003eWhat exactly is \u003ca href\u003d\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.correlate.html\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003enumpy.correlate\u003c/code\u003e\u003c/a\u003e doing?\u003c/li\u003e \u003cli\u003eHow can I use it (or something else) to do auto-correlation?\u003c/li\u003e \u003c/ol\u003e",  "answers_body": "\u003cp\u003eI think the real answer to the OP\u0027s question is succinctly contained in this excerpt from the Numpy.correlate documentation:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003emode : {\u0027valid\u0027; \u0027same\u0027; \u0027full\u0027}; optional     Refer to the `convolve` docstring.  Note that the default     is `valid`; unlike `convolve`; which uses `full`. \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis implies that; when used with no \u0027mode\u0027 definition; the Numpy.correlate function will return a scalar; when given the same vector for its two input arguments (i.e. - when used to perform autocorrelation).\u003c/p\u003e"}
{  "id": "13370570",  "f0_": "Elegant grid search in python/numpy",  "f1_": "python|numpy",  "answer_count": "4",  "question_scoer": "31",  "questions_creation_date": "2012-11-13T23:18:17.383Z",  "answers_score": "1",  "answers_creation_date": "2015-01-22T15:31:15.787Z",  "questions_body": "\u003cp\u003eI have a function that has a bunch of parameters. Rather than setting all of the parameters manually; I want to perform a grid search. I have a list of possible values for each parameter. For every possible combination of parameters; I want to run my function which reports the performance of my algorithm on those parameters. I want to store the results of this in a many-dimensional matrix; so that afterwords I can just find the index of the maximum performance; which would in turn give me the best parameters. Here is how the code is written now:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eparam1_list \u003d [p11; p12; p13;...] param2_list \u003d [p21; p22; p23;...] # not necessarily the same number of values ...  results_size \u003d (len(param1_list); len(param2_list);...) results \u003d np.zeros(results_size; dtype \u003d np.float)  for param1_idx in range(len(param1_list)):   for param2_idx in range(len(param2_list)):     ...     param1 \u003d param1_list[param1_idx]     param2 \u003d param2_list[param2_idx]     ...     results[param1_idx; param2_idx; ...] \u003d my_func(param1; param2; ...)  max_index \u003d np.argmax(results) # indices of best parameters! \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI want to keep the first part; where I define the lists as-is; since I want to easily be able to manipulate the values over which I search.\u003c/p\u003e  \u003cp\u003eI also want to end up with the results matrix as is; since I will be visualizing how changing different parameters affects the performance of the algorithm.\u003c/p\u003e  \u003cp\u003eThe bit in the middle; though; is quite repetitive and bulky (especially because I have lots of parameters; and I might want to add or remove parameters); and I feel like there should be a more succinct/elegant way to initialize the results matrix; iterate over all of the indices; and set the appropriate parameters.\u003c/p\u003e  \u003cp\u003eSo; is there?\u003c/p\u003e",  "answers_body": "\u003cp\u003eYou may use numpy \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html#numpy.meshgrid\" rel\u003d\"nofollow\"\u003e\u003ccode\u003emeshgrid\u003c/code\u003e\u003c/a\u003e for this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np  x \u003d range(1; 5) y \u003d range(10)  xx; yy \u003d np.meshgrid(x; y) results \u003d my_func(xx; yy) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003enote that your function must be able to work with \u003ccode\u003enumpy.array\u003c/code\u003es.\u003c/p\u003e"}
{  "id": "17443354",  "f0_": "Install numpy on python3.3 - Install pip for python3",  "f1_": "numpy|python-3.x",  "answer_count": "6",  "question_scoer": "38",  "questions_creation_date": "2013-07-03T08:38:29.683Z",  "answers_score": "1",  "answers_creation_date": "2015-01-23T23:26:47.160Z",  "questions_body": "\u003cp\u003eFor python 3.2 I used \u003ccode\u003esudo apt-get install python3.2-numpy\u003c/code\u003e.It worked. What to do for python3.3? Nothing I could think of works. Same goes for scipy; etc. Thanks.\u003c/p\u003e  \u003cp\u003eEdit: this is how it looks like\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eradu@sunlit-inspired:~$ python3 Python 3.3.2 (default; Jul  3 2013; 10:17:40)  [GCC 4.6.3] on linux Type \"help\"; \"copyright\"; \"credits\" or \"license\" for more information. \u0026gt;\u0026gt;\u0026gt; import numpy Traceback (most recent call last):   File \"\u0026lt;stdin\u0026gt;\"; line 1; in \u0026lt;module\u0026gt; ImportError: No module named \u0027numpy\u0027 \u003c/code\u003e\u003c/pre\u003e",  "answers_body": "\u003cp\u003eOn fedora/rhel/centos you need to \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003esudo yum install -y python3-devel \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebefore \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003emkvirtualenv -p /usr/bin/python3.3 test-3.3 pip install numpy \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eotherwise you\u0027ll get\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eSystemError: Cannot compile \u0027Python.h\u0027. Perhaps you need to install python-dev|python-devel. \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "2891790",  "f0_": "How to pretty-print a numpy.array without scientific notation and with given precision?",  "f1_": "python|numpy|python-2.x|pretty-print",  "answer_count": "14",  "question_scoer": "405",  "questions_creation_date": "2010-05-23T12:54:29.077Z",  "answers_score": "1",  "answers_creation_date": "2015-02-02T21:06:41.260Z",  "questions_body": "\u003cp\u003eI\u0027m curious; whether there is any way to print formatted \u003ccode\u003enumpy.arrays\u003c/code\u003e; e.g.; in a way similar to this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ex \u003d 1.23456 print \u0027%.3f\u0027 % x \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIf I want to print the \u003ccode\u003enumpy.array\u003c/code\u003e of floats; it prints several decimals; often in \u0027scientific\u0027 format; which is rather hard to read even for low-dimensional arrays. However; \u003ccode\u003enumpy.array\u003c/code\u003e apparently has to be printed as a string; i.e.; with \u003ccode\u003e%s\u003c/code\u003e. Is there a solution for this? \u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.core.defchararray.mod.html#numpy.core.defchararray.mod\" rel\u003d\"nofollow\"\u003e\u003ccode\u003enumpy.char.mod\u003c/code\u003e\u003c/a\u003e may also be useful; depending on the details of your application e.g.:\u003ccode\u003enumpy.char.mod(\u0027Value\u003d%4.2f\u0027; numpy.arange(5; 10; 0.1))\u003c/code\u003e will return a string array with elements \"Value\u003d5.00\"; \"Value\u003d5.10\" etc. (as a somewhat contrived example).\u003c/p\u003e"}
{  "id": "22956139",  "f0_": "Why does numpy.power return 0 for small exponents while math.pow returns the correct answer?",  "f1_": "python|numpy|exponentiation",  "answer_count": "3",  "question_scoer": "54",  "questions_creation_date": "2014-04-09T07:52:37.547Z",  "answers_score": "1",  "answers_creation_date": "2015-02-04T21:31:34.347Z",  "questions_body": "\u003cpre\u003e\u003ccode\u003eIn [25]: np.power(10;-100) Out[25]: 0  In [26]: math.pow(10;-100) Out[26]: 1e-100 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI would expect both the commands to return 1e-100. This is not a precision issue either; since the issue persists even after increasing precision to 500. Is there some setting which I can change to get the correct answer?\u003c/p\u003e",  "answers_body": "\u003cp\u003e(Just a footnote to the two other answers on this page.)\u003c/p\u003e  \u003cp\u003eGiven input two input values; you can check the datatype of the object that \u003ccode\u003enp.power\u003c/code\u003e will return by inspecting the \u003ccode\u003etypes\u003c/code\u003e attribute:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; np.power.types [\u0027bb-\u0026gt;b\u0027; \u0027BB-\u0026gt;B\u0027; \u0027hh-\u0026gt;h\u0027; \u0027HH-\u0026gt;H\u0027; \u0027ii-\u0026gt;i\u0027; \u0027II-\u0026gt;I\u0027; \u0027ll-\u0026gt;l\u0027; \u0027LL-\u0026gt;L\u0027; \u0027qq-\u0026gt;q\u0027;   \u0027QQ-\u0026gt;Q\u0027; \u0027ee-\u0026gt;e\u0027; \u0027ff-\u0026gt;f\u0027; \u0027dd-\u0026gt;d\u0027; \u0027gg-\u0026gt;g\u0027; \u0027FF-\u0026gt;F\u0027; \u0027DD-\u0026gt;D\u0027; \u0027GG-\u0026gt;G\u0027; \u0027OO-\u0026gt;O\u0027] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ePython-compatible integer types are denoted by \u003ccode\u003el\u003c/code\u003e; compatible-compatible Python floats by \u003ccode\u003ed\u003c/code\u003e (\u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html#arrays-scalars-character-codes\" rel\u003d\"nofollow\"\u003edocuments\u003c/a\u003e).\u003c/p\u003e  \u003cp\u003e\u003ccode\u003enp.power\u003c/code\u003e effectively decides what to return by checking the types of the arguments passed and using the first matching signature from this list.\u003c/p\u003e  \u003cp\u003eSo given 10 and -100; \u003ccode\u003enp.power\u003c/code\u003e matches the \u003ccode\u003einteger integer -\u0026gt; integer\u003c/code\u003e signature and returns the integer \u003ccode\u003e0\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003eOn the other hand; if one of the arguments is a float then \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/ufuncs.html#ufuncs-casting\" rel\u003d\"nofollow\"\u003ethe integer argument will also be cast to a float\u003c/a\u003e; and the \u003ccode\u003efloat float -\u0026gt; float\u003c/code\u003e signature is used (and the correct float value is returned).\u003c/p\u003e"}
{  "id": "15579649",  "f0_": "python dict to numpy structured array",  "f1_": "python|numpy|arcpy",  "answer_count": "5",  "question_scoer": "45",  "questions_creation_date": "2013-03-22T20:51:49.720Z",  "answers_score": "3",  "answers_creation_date": "2015-02-18T08:35:12.637Z",  "questions_body": "\u003cp\u003eI have a dictionary that I need to convert to a NumPy structured array.  I\u0027m using the arcpy function \u003ca href\u003d\"http://resources.arcgis.com/en/help/main/10.1/index.html#//018w00000016000000\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003eNumPyArraytoTable\u003c/code\u003e\u003c/a\u003e; so a NumPy structured array is the only data format that will work.  \u003c/p\u003e  \u003cp\u003eBased on this thread: \u003ca href\u003d\"https://stackoverflow.com/questions/10838982/writing-to-numpy-array-from-dictionary\"\u003eWriting to numpy array from dictionary\u003c/a\u003e and this thread: \u003ca href\u003d\"https://stackoverflow.com/questions/7471872/how-to-convert-python-dictionary-object-to-numpy-array\"\u003eHow to convert Python dictionary object to numpy array\u003c/a\u003e\u003c/p\u003e  \u003cp\u003eI\u0027ve tried this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eresult \u003d {0: 1.1181753789488595; 1: 0.5566080288678394; 2: 0.4718269778030734; 3: 0.48716683119447185; 4: 1.0; 5: 0.1395076201641266; 6: 0.20941558441558442}  names \u003d [\u0027id\u0027;\u0027data\u0027] formats \u003d [\u0027f8\u0027;\u0027f8\u0027] dtype \u003d dict(names \u003d names; formats\u003dformats) array\u003dnumpy.array([[key;val] for (key;val) in result.iteritems()];dtype) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eBut I keep getting \u003ccode\u003eexpected a readable buffer object\u003c/code\u003e\u003c/p\u003e  \u003cp\u003eThe method below works; but is stupid and obviously won\u0027t work for real data. I know there is a more graceful approach; I just can\u0027t figure it out.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003etotable \u003d numpy.array([[key;val] for (key;val) in result.iteritems()]) array\u003dnumpy.array([(totable[0;0];totable[0;1]);(totable[1;0];totable[1;1])];dtype) \u003c/code\u003e\u003c/pre\u003e",  "answers_body": "\u003cp\u003eLet me propose an improved method when the values of the dictionnary are lists with the same lenght :\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy  def dctToNdarray (dd; szFormat \u003d \u0027f8\u0027):     \u0027\u0027\u0027     Convert a \u0027rectangular\u0027 dictionnary to numpy NdArray     entry          dd : dictionnary (same len of list      retrun         data : numpy NdArray      \u0027\u0027\u0027     names \u003d dd.keys()     firstKey \u003d dd.keys()[0]     formats \u003d [szFormat]*len(names)     dtype \u003d dict(names \u003d names; formats\u003dformats)     values \u003d [tuple(dd[k][0] for k in dd.keys())]     data \u003d numpy.array(values; dtype\u003ddtype)     for i in range(1;len(dd[firstKey])) :         values \u003d [tuple(dd[k][i] for k in dd.keys())]         data_tmp \u003d numpy.array(values; dtype\u003ddtype)         data \u003d numpy.concatenate((data;data_tmp))     return data  dd \u003d {\u0027a\u0027:[1;2.05;25.48];\u0027b\u0027:[2;1.07;9];\u0027c\u0027:[3;3.01;6.14]} data \u003d dctToNdarray(dd) print data.dtype.names print data \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28439701",  "f0_": "How to save and load numpy.array() data properly?",  "f1_": "python|arrays|numpy",  "answer_count": "4",  "question_scoer": "133",  "questions_creation_date": "2015-02-10T19:02:18.577Z",  "answers_score": "4",  "answers_creation_date": "2015-02-10T19:54:43.797Z",  "questions_body": "\u003cp\u003eI wonder; how to save and load \u003ccode\u003enumpy.array\u003c/code\u003e data properly. Currently I\u0027m using the \u003ccode\u003enumpy.savetxt()\u003c/code\u003e method. For example; if I got an array \u003ccode\u003emarkers\u003c/code\u003e; which looks like this:\u003c/p\u003e  \u003cp\u003e\u003cimg src\u003d\"https://i.stack.imgur.com/gpbT1.png\" alt\u003d\"enter image description here\"\u003e\u003c/p\u003e  \u003cp\u003eI try to save it by the use of:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enumpy.savetxt(\u0027markers.txt\u0027; markers) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIn other script I try to open previously saved file:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003emarkers \u003d np.fromfile(\"markers.txt\") \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAnd that\u0027s what I get...\u003c/p\u003e  \u003cp\u003e\u003cimg src\u003d\"https://i.stack.imgur.com/bO0CB.png\" alt\u003d\"enter image description here\"\u003e\u003c/p\u003e  \u003cp\u003eSaved data first looks like this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eBut when I save just loaded data by the use of the same method; ie. \u003ccode\u003enumpy.savetxt()\u003c/code\u003e it looks like this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e1.398043286095131769e-76 1.398043286095288860e-76 1.396426376485745879e-76 1.398043286055061908e-76 1.398043286095288860e-76 1.182950697433698368e-76 1.398043275797188953e-76 1.398043286095288860e-76 1.210894289234927752e-99 1.398040649781712473e-76 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eWhat am I doing wrong? PS there are no other \"backstage\" operation which I perform. Just saving and loading; and that\u0027s what I get. Thank you in advance.\u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.fromfile.html\" rel\u003d\"nofollow\"\u003e\u003ccode\u003enp.fromfile()\u003c/code\u003e\u003c/a\u003e has a \u003ccode\u003esep\u003d\u003c/code\u003e keyword argument:\u003c/p\u003e  \u003cblockquote\u003e   \u003cp\u003eSeparator between items if file is a text file. Empty (“”) separator means the file should be treated as binary. Spaces (” ”) in the separator match zero or more whitespace characters. A separator consisting only of spaces must match at least one whitespace.\u003c/p\u003e \u003c/blockquote\u003e  \u003cp\u003eThe default value of \u003ccode\u003esep\u003d\"\"\u003c/code\u003e means that \u003ccode\u003enp.fromfile()\u003c/code\u003e tries to read it as a binary file rather than a space-separated text file; so you get nonsense values back. If you use \u003ccode\u003enp.fromfile(\u0027markers.txt\u0027; sep\u003d\" \")\u003c/code\u003e you will get the result you are looking for.\u003c/p\u003e  \u003cp\u003eHowever; as others have pointed out; \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html#numpy.loadtxt\" rel\u003d\"nofollow\"\u003e\u003ccode\u003enp.loadtxt()\u003c/code\u003e\u003c/a\u003e is the preferred way to convert text files to numpy arrays; and unless the file needs to be human-readable it is usually better to use binary formats instead (e.g. \u003ccode\u003enp.load()\u003c/code\u003e/\u003ccode\u003enp.save()\u003c/code\u003e).\u003c/p\u003e"}
{  "id": "28697993",  "f0_": "numpy: what is the logic of the argmin() and argmax() functions?",  "f1_": "python|arrays|numpy|argmax",  "answer_count": "5",  "question_scoer": "31",  "questions_creation_date": "2015-02-24T14:10:57.290Z",  "answers_score": "5",  "answers_creation_date": "2015-02-24T14:24:12.553Z",  "questions_body": "\u003cp\u003eI can not understand the output of \u003ccode\u003eargmax\u003c/code\u003e and \u003ccode\u003eargmin\u003c/code\u003e when use with the axis parameter. For example:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; a \u003d np.array([[1;2;4;7]; [9;88;6;45]; [9;76;3;4]]) \u0026gt;\u0026gt;\u0026gt; a array([[ 1;  2;  4;  7];        [ 9; 88;  6; 45];        [ 9; 76;  3;  4]]) \u0026gt;\u0026gt;\u0026gt; a.shape (3; 4) \u0026gt;\u0026gt;\u0026gt; a.size 12 \u0026gt;\u0026gt;\u0026gt; np.argmax(a) 5 \u0026gt;\u0026gt;\u0026gt; np.argmax(a;axis\u003d0) array([1; 1; 1; 1]) \u0026gt;\u0026gt;\u0026gt; np.argmax(a;axis\u003d1) array([3; 1; 1]) \u0026gt;\u0026gt;\u0026gt; np.argmin(a) 0 \u0026gt;\u0026gt;\u0026gt; np.argmin(a;axis\u003d0) array([0; 0; 2; 2]) \u0026gt;\u0026gt;\u0026gt; np.argmin(a;axis\u003d1) array([0; 2; 2]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAs you can see; the maximum value is the point (1;1) and the minimum one is the point (0;0). So in my logic when I run:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003ccode\u003enp.argmin(a;axis\u003d0)\u003c/code\u003e I expected \u003ccode\u003earray([0;0;0;0])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmin(a;axis\u003d1)\u003c/code\u003e I expected \u003ccode\u003earray([0;0;0])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmax(a;axis\u003d0)\u003c/code\u003e I expected \u003ccode\u003earray([1;1;1;1])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmax(a;axis\u003d1)\u003c/code\u003e I expected \u003ccode\u003earray([1;1;1])\u003c/code\u003e \u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eWhat is wrong with my understanding of things?\u003c/p\u003e",  "answers_body": "\u003cp\u003eThe \u003ccode\u003enp.argmax\u003c/code\u003e function by default works \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\" rel\u003d\"noreferrer\"\u003ealong the flattened array\u003c/a\u003e; unless you specify an axis. To see what is happening you can use \u003ccode\u003eflatten\u003c/code\u003e explicitly:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enp.argmax(a) \u0026gt;\u0026gt;\u0026gt; 5  a.flatten() \u0026gt;\u0026gt;\u0026gt;\u0026gt; array([ 1;  2;  4;  7;  9; 88;  6; 45;  9; 76;  3;  4])              0   1   2   3   4   5  \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI\u0027ve numbered the indices under the array above to make it clearer. Note that indices are numbered from zero in \u003ccode\u003enumpy\u003c/code\u003e. \u003c/p\u003e  \u003cp\u003eIn the cases where you specify the axis; it is also working as expected:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enp.argmax(a;axis\u003d0) \u0026gt;\u0026gt;\u0026gt; array([1; 1; 1; 1]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis tells you that the largest value is in row \u003ccode\u003e1\u003c/code\u003e (2nd value); for each column along \u003ccode\u003eaxis\u003d0\u003c/code\u003e (down). You can see this more clearly if you change your data a bit:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ea\u003dnp.array([[100;2;4;7];[9;88;6;45];[9;76;3;100]]) a \u0026gt;\u0026gt;\u0026gt; array([[100;   2;   4;   7];            [  9;  88;   6;  45];            [  9;  76;   3; 100]])  np.argmax(a; axis\u003d0) \u0026gt;\u0026gt;\u0026gt; array([0; 1; 1; 2]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAs you can see it now identifies the maximum value in row 0 for column 1; row 1 for column 2 and 3 and row 3 for column 4.\u003c/p\u003e  \u003cp\u003eThere is a useful guide to \u003ccode\u003enumpy\u003c/code\u003e indexing in the \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html\" rel\u003d\"noreferrer\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e"}
{  "id": "28283112",  "f0_": "Using mkl_set_num_threads with numpy",  "f1_": "python|numpy|intel-mkl",  "answer_count": "4",  "question_scoer": "16",  "questions_creation_date": "2015-02-02T17:17:29.740Z",  "answers_score": "8",  "answers_creation_date": "2015-02-03T07:42:40.520Z",  "questions_body": "\u003cp\u003eI\u0027m trying to set the number of threads for numpy calculations with \u003ccode\u003emkl_set_num_threads\u003c/code\u003e like this\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy import ctypes mkl_rt \u003d ctypes.CDLL(\u0027libmkl_rt.so\u0027) mkl_rt.mkl_set_num_threads(4) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut I keep getting an segmentation fault:\u003c/p\u003e  \u003cpre class\u003d\"lang-none prettyprint-override\"\u003e\u003ccode\u003eProgram received signal SIGSEGV; Segmentation fault. 0x00002aaab34d7561 in mkl_set_num_threads__ () from /../libmkl_intel_lp64.so \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eGetting the number of threads is no problem:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eprint mkl_rt.mkl_get_max_threads() \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow can I get my code working? Or is there another way to set the number of threads at runtime?\u003c/p\u003e",  "answers_body": "\u003cp\u003eLong story short; use \u003ccode\u003eMKL_Set_Num_Threads\u003c/code\u003e and its CamelCased friends when calling MKL from Python.  The same applies to C if you don\u0027t \u003ccode\u003e#include \u0026lt;mkl.h\u0026gt;\u003c/code\u003e.\u003c/p\u003e  \u003chr\u003e  \u003cp\u003eThe \u003ca href\u003d\"https://software.intel.com/en-us/node/471134\" rel\u003d\"noreferrer\"\u003eMKL documentation\u003c/a\u003e seems to suggest that the correct type signature in C is:\u003c/p\u003e  \u003cpre class\u003d\"lang-c prettyprint-override\"\u003e\u003ccode\u003evoid mkl_set_num_threads(int nt); \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eOkay; let\u0027s try a minimal program then:\u003c/p\u003e  \u003cpre class\u003d\"lang-c prettyprint-override\"\u003e\u003ccode\u003evoid mkl_set_num_threads(int); int main(void) {     mkl_set_num_threads(1);     return 0; } \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eCompile it with GCC and \u003cem\u003eboom\u003c/em\u003e; \u003ccode\u003eSegmentation fault\u003c/code\u003e again.  So it seems the problem isn\u0027t restricted to Python.\u003c/p\u003e  \u003cp\u003eRunning it through a debugger (GDB) reveals:\u003c/p\u003e  \u003cpre class\u003d\"lang-none prettyprint-override\"\u003e\u003ccode\u003eProgram received signal SIGSEGV; Segmentation fault. 0x0000… in mkl_set_num_threads_ ()    from /…/mkl/lib/intel64/libmkl_intel_lp64.so \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eWait a second; \u003ccode\u003emkl_set_num_threads_\u003c/code\u003e??  That\u0027s the \u003cem\u003eFortran version\u003c/em\u003e of \u003ccode\u003emkl_set_num_threads\u003c/code\u003e!  How did we end up calling the Fortran version?  (Keep in mind that Fortran\u0027s calling convention requires arguments to be passed as \u003cem\u003epointers\u003c/em\u003e rather than by value.)\u003c/p\u003e  \u003cp\u003eIt turns out the documentation was a complete façade.  If you actually inspect the header files for the recent versions of MKL; you will find this cute little definition:\u003c/p\u003e  \u003cpre class\u003d\"lang-c prettyprint-override\"\u003e\u003ccode\u003evoid    MKL_Set_Num_Threads(int nth); #define mkl_set_num_threads         MKL_Set_Num_Threads \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e… and now everything makes sense!  The correct function do call (for C code) is \u003ccode\u003eMKL_Set_Num_Threads\u003c/code\u003e; not \u003ccode\u003emkl_set_num_threads\u003c/code\u003e.  Inspecting the symbol table reveals that there are actually \u003cem\u003efour different variants\u003c/em\u003e defined:\u003c/p\u003e  \u003cpre class\u003d\"lang-none prettyprint-override\"\u003e\u003ccode\u003enm -D /…/mkl/lib/intel64/libmkl_rt.so | grep -i mkl_set_num_threads 00000000000e3060 T MKL_SET_NUM_THREADS … 00000000000e30b0 T MKL_Set_Num_Threads … 00000000000e3060 T mkl_set_num_threads 00000000000e3060 T mkl_set_num_threads_ … \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eWhy did Intel put in four different variants of one function despite there being only C and Fortran variants in the documentation?  I don\u0027t know for certain; but I suspect it\u0027s for compatibility with different Fortran compilers.  You see; Fortran calling convention is not standardized.  Different compilers will \u003ca href\u003d\"https://en.wikipedia.org/wiki/Name_mangling#Name_mangling_in_Fortran\" rel\u003d\"noreferrer\"\u003emangle the names\u003c/a\u003e of the functions differently:\u003c/p\u003e  \u003cul\u003e \u003cli\u003esome use upper case;\u003c/li\u003e \u003cli\u003esome use lower case with a trailing underscore; and\u003c/li\u003e \u003cli\u003esome use lower case with no decoration at all.\u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eThere may even be other ways that I\u0027m not aware of.  This trick allows the MKL library to be used with \u003cem\u003emost Fortran compilers\u003c/em\u003e without any modification; the downside being that C functions need to be \"mangled\" to make room for the 3 variants of the Fortran calling convention.\u003c/p\u003e"}
{  "id": "5613244",  "f0_": "root mean square in numpy and complications of matrix and arrays of numpy",  "f1_": "python|numpy",  "answer_count": "7",  "question_scoer": "19",  "questions_creation_date": "2011-04-10T16:53:02.173Z",  "answers_score": "12",  "answers_creation_date": "2015-02-08T19:04:41.943Z",  "questions_body": "\u003cp\u003eCan anyone direct me to the section of numpy manual where i can get functions to accomplish root mean square calculations ...  (i know this can be accomplished using np.mean and np.abs .. isn\u0027t there a built in ..if no why?? .. just curious ..no offense)\u003c/p\u003e  \u003cp\u003ecan anyone explain the complications of matrix and arrays (just in the following case):\u003c/p\u003e  \u003cp\u003e\u003ccode\u003eU\u003c/code\u003e is a matrix(T-by-N;or u say T cross N) ; \u003ccode\u003eUe\u003c/code\u003e is another matrix(T-by-N) I define \u003ccode\u003ek\u003c/code\u003e as a numpy array\u003c/p\u003e  \u003cp\u003e\u003ccode\u003eU[ind;:]\u003c/code\u003e is still matrix\u003c/p\u003e  \u003cp\u003ein the following fashion \u003ccode\u003ek \u003d np.array(U[ind;:])\u003c/code\u003e\u003c/p\u003e  \u003cp\u003ewhen I print \u003ccode\u003ek\u003c/code\u003e or type \u003ccode\u003ek\u003c/code\u003e in ipython\u003c/p\u003e  \u003cp\u003eit displays following\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eK \u003d array ([[2;.3 .....               ......                 9]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eYou see the double square brackets (which makes it multi-dim i guess) which gives it the shape \u003d (1;N)\u003c/p\u003e  \u003cp\u003ebut I can\u0027t assign it to array defined in this way\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003el \u003d np.zeros(N) shape \u003d (;N) or perhaps (N;) something like that  l[:] \u003d k[:] error: matrix dimensions incompatible \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIs there a way to accomplish the vector assignment which I intend to do ... Please don\u0027t tell me do this \u003ccode\u003el \u003d k\u003c/code\u003e (that defeats the purpose ... I get different errors in program .. I know the reasons ..If you need I may attach the piece of code)\u003c/p\u003e  \u003cp\u003ewriting a loop is the dumb way .. which I\u0027m using for the time being ...\u003c/p\u003e  \u003cp\u003eI hope I was able to explain .. the problems I\u0027m facing ..\u003c/p\u003e  \u003cp\u003eregards ...\u003c/p\u003e",  "answers_body": "\u003cp\u003eFor rms; the \u003cstrong\u003efastest\u003c/strong\u003e expression I have found for small \u003ccode\u003ex.size\u003c/code\u003e (~ 1024) and real \u003ccode\u003ex\u003c/code\u003e is:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef rms(x):     return np.sqrt(x.dot(x)/x.size) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis seems to be around twice as fast as the \u003ccode\u003elinalg.norm\u003c/code\u003e version (ipython %timeit on a \u003cem\u003ereally\u003c/em\u003e old laptop).\u003c/p\u003e  \u003cp\u003eIf you want complex arrays handled more appropriately then this also would work:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef rms(x):     return np.sqrt(np.vdot(x; x)/x.size) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHowever; this version is nearly as slow as the \u003ccode\u003enorm\u003c/code\u003e version and only works for flat arrays. \u003c/p\u003e"}
{  "id": "28283112",  "f0_": "Using mkl_set_num_threads with numpy",  "f1_": "python|numpy|intel-mkl",  "answer_count": "4",  "question_scoer": "16",  "questions_creation_date": "2015-02-02T17:17:29.740Z",  "answers_score": "16",  "answers_creation_date": "2015-02-03T07:01:28.697Z",  "questions_body": "\u003cp\u003eI\u0027m trying to set the number of threads for numpy calculations with \u003ccode\u003emkl_set_num_threads\u003c/code\u003e like this\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy import ctypes mkl_rt \u003d ctypes.CDLL(\u0027libmkl_rt.so\u0027) mkl_rt.mkl_set_num_threads(4) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut I keep getting an segmentation fault:\u003c/p\u003e  \u003cpre class\u003d\"lang-none prettyprint-override\"\u003e\u003ccode\u003eProgram received signal SIGSEGV; Segmentation fault. 0x00002aaab34d7561 in mkl_set_num_threads__ () from /../libmkl_intel_lp64.so \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eGetting the number of threads is no problem:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eprint mkl_rt.mkl_get_max_threads() \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow can I get my code working? Or is there another way to set the number of threads at runtime?\u003c/p\u003e",  "answers_body": "\u003cp\u003eOphion led me the right way. Despite the documentation; one have to transfer the parameter of \u003ccode\u003emkl_set_num_thread\u003c/code\u003e by reference. \u003c/p\u003e  \u003cp\u003eNow I have defined to functions; for getting and setting the threads\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy import ctypes mkl_rt \u003d ctypes.CDLL(\u0027libmkl_rt.so\u0027) mkl_get_max_threads \u003d mkl_rt.mkl_get_max_threads def mkl_set_num_threads(cores):     mkl_rt.mkl_set_num_threads(ctypes.byref(ctypes.c_int(cores)))  mkl_set_num_threads(4) print mkl_get_max_threads() # says 4 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eand they work as expected.\u003c/p\u003e  \u003cp\u003eEdit: according to Rufflewind; the names of the C-Functions are written in capital-case; which expect parameters by value:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport ctypes  mkl_rt \u003d ctypes.CDLL(\u0027libmkl_rt.so\u0027) mkl_set_num_threads \u003d mkl_rt.MKL_Set_Num_Threads mkl_get_max_threads \u003d mkl_rt.MKL_Get_Max_Threads \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28491230",  "f0_": "Indexing a numpy array with a list of tuples",  "f1_": "numpy|multidimensional-array|indices",  "answer_count": "2",  "question_scoer": "41",  "questions_creation_date": "2015-02-13T01:46:38.560Z",  "answers_score": "56",  "answers_creation_date": "2015-02-13T02:51:37.743Z",  "questions_body": "\u003cp\u003eWhy can\u0027t I index an ndarray using a list of tuple indices like so?\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eidx \u003d [(x1; y1); ... (xn; yn)] X[idx] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eInstead I have to do something unwieldy like\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eidx2 \u003d numpy.array(idx) X[idx2[:; 0]; idx2[:; 1]] # or more generally: X[tuple(numpy.vsplit(idx2.T; 1)[0])] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIs there a simpler; more pythonic way?\u003c/p\u003e",  "answers_body": "\u003cp\u003eYou can use a list of tuples; but the convention is different from what you want.  \u003ccode\u003enumpy\u003c/code\u003e expects a list of row indices; followed by a list of column values.  You; apparently; want to specify a list of (x;y) pairs.\u003c/p\u003e  \u003cp\u003e\u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#integer-array-indexing\"\u003ehttp://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#integer-array-indexing\u003c/a\u003e The relevant section in the documentation is \u0027integer array indexing\u0027.\u003c/p\u003e  \u003chr\u003e  \u003cp\u003eHere\u0027s an example; seeking 3 points in a 2d array.  (2 points in 2d can be confusing):\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [223]: idx Out[223]: [(0; 1; 1); (2; 3; 0)] In [224]: X[idx] Out[224]: array([2; 7; 4]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eUsing your style of xy pairs of indices:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [230]: idx1 \u003d [(0;2);(1;3);(1;0)] In [231]: [X[i] for i in idx1] Out[231]: [2; 7; 4]  In [240]: X[tuple(np.array(idx1).T)] Out[240]: array([2; 7; 4]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e\u003ccode\u003eX[tuple(zip(*idx1))]\u003c/code\u003e is another way of doing the conversion.  The \u003ccode\u003etuple()\u003c/code\u003e is optional in Python2.  \u003ccode\u003ezip(*...)\u003c/code\u003e is a Python idiom that reverses the nesting of a list of lists.\u003c/p\u003e  \u003cp\u003eYou are on the right track with:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [242]: idx2\u003dnp.array(idx1) In [243]: X[idx2[:;0]; idx2[:;1]] Out[243]: array([2; 7; 4]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eMy \u003ccode\u003etuple()\u003c/code\u003e is just a bit more compact (and not necessarily more \u0027pythonic\u0027).   Given the \u003ccode\u003enumpy\u003c/code\u003e convention; some sort of conversion is necessary.\u003c/p\u003e  \u003cp\u003e(Should we check what works with n-dimensions and m-points?)\u003c/p\u003e"}
{  "id": "28125265",  "f0_": "concatenate numpy arrays which are elements of a list",  "f1_": "python|arrays|list|numpy",  "answer_count": "2",  "question_scoer": "39",  "questions_creation_date": "2015-01-24T12:02:31.350Z",  "answers_score": "65",  "answers_creation_date": "2015-01-24T12:06:30.923Z",  "questions_body": "\u003cp\u003eI have a list containing numpy arrays something like L\u003d[a;b;c] where a; b and c are numpy arrays with sizes N_a in T; N_b in T and N_c in T.\u003cbr\u003e I want to row-wise concatenate a; b and c and get a numpy array with shape (N_a+N_b+N_c; T). Clearly one solution is run a for loop and use numpy.concatenate; but is there any pythonic way to do this?\u003c/p\u003e  \u003cp\u003eThanks\u003c/p\u003e",  "answers_body": "\u003cp\u003eUse \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html#numpy.vstack\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003enumpy.vstack\u003c/code\u003e\u003c/a\u003e.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eL \u003d (a;b;c) arr \u003d np.vstack(L) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "2284611",  "f0_": "Sum of Square Differences (SSD) in numpy/scipy",  "f1_": "python|image-processing|numpy|scipy",  "answer_count": "7",  "question_scoer": "16",  "questions_creation_date": "2010-02-17T21:43:37.897Z",  "answers_score": "-3",  "answers_creation_date": "2015-01-29T11:54:14.157Z",  "questions_body": "\u003cp\u003eI\u0027m trying to use Python and Numpy/Scipy to implement an image processing algorithm. The profiler tells me a lot of time is being spent in the following function (called often); which tells me the sum of square differences between two images\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef ssd(A;B):     s \u003d 0     for i in range(3):         s +\u003d sum(pow(A[:;:;i] - B[:;:;i];2))     return s \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow can I speed this up? Thanks.\u003c/p\u003e",  "answers_body": "\u003cp\u003eIn Ruby language you can achieve this in this way\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef diff_btw_sum_of_squars_and_squar_of_sum(from\u003d1;to\u003d100) # use default values from 1..100.  ((1..100).inject(:+)**2) -(1..100).map {|num| num ** 2}.inject(:+) end  diff_btw_sum_of_squars_and_squar_of_sum #call for above method \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28697993",  "f0_": "numpy: what is the logic of the argmin() and argmax() functions?",  "f1_": "python|arrays|numpy|argmax",  "answer_count": "5",  "question_scoer": "31",  "questions_creation_date": "2015-02-24T14:10:57.290Z",  "answers_score": "1",  "answers_creation_date": "2015-02-24T14:26:54.887Z",  "questions_body": "\u003cp\u003eI can not understand the output of \u003ccode\u003eargmax\u003c/code\u003e and \u003ccode\u003eargmin\u003c/code\u003e when use with the axis parameter. For example:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; a \u003d np.array([[1;2;4;7]; [9;88;6;45]; [9;76;3;4]]) \u0026gt;\u0026gt;\u0026gt; a array([[ 1;  2;  4;  7];        [ 9; 88;  6; 45];        [ 9; 76;  3;  4]]) \u0026gt;\u0026gt;\u0026gt; a.shape (3; 4) \u0026gt;\u0026gt;\u0026gt; a.size 12 \u0026gt;\u0026gt;\u0026gt; np.argmax(a) 5 \u0026gt;\u0026gt;\u0026gt; np.argmax(a;axis\u003d0) array([1; 1; 1; 1]) \u0026gt;\u0026gt;\u0026gt; np.argmax(a;axis\u003d1) array([3; 1; 1]) \u0026gt;\u0026gt;\u0026gt; np.argmin(a) 0 \u0026gt;\u0026gt;\u0026gt; np.argmin(a;axis\u003d0) array([0; 0; 2; 2]) \u0026gt;\u0026gt;\u0026gt; np.argmin(a;axis\u003d1) array([0; 2; 2]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAs you can see; the maximum value is the point (1;1) and the minimum one is the point (0;0). So in my logic when I run:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003ccode\u003enp.argmin(a;axis\u003d0)\u003c/code\u003e I expected \u003ccode\u003earray([0;0;0;0])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmin(a;axis\u003d1)\u003c/code\u003e I expected \u003ccode\u003earray([0;0;0])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmax(a;axis\u003d0)\u003c/code\u003e I expected \u003ccode\u003earray([1;1;1;1])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmax(a;axis\u003d1)\u003c/code\u003e I expected \u003ccode\u003earray([1;1;1])\u003c/code\u003e \u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eWhat is wrong with my understanding of things?\u003c/p\u003e",  "answers_body": "\u003cp\u003eThe axis in the argmax function argument; refers to the axis along which the array will be sliced. \u003c/p\u003e  \u003cp\u003eIn another word; \u003ccode\u003enp.argmin(a;axis\u003d0)\u003c/code\u003e is effectively the same as \u003ccode\u003enp.apply_along_axis(np.argmin; 0; a)\u003c/code\u003e; that is to find out the minimum location for these sliced vectors along the axis\u003d0.\u003c/p\u003e  \u003cp\u003eTherefore in your example; \u003ccode\u003enp.argmin(a; axis\u003d0)\u003c/code\u003e is \u003ccode\u003e[0; 0; 2; 2]\u003c/code\u003e which corresponding to values of \u003ccode\u003e[1; 2; 3; 4]\u003c/code\u003e on respective columns\u003c/p\u003e"}
{  "id": "28524378",  "f0_": "Convert map object to numpy array in python 3",  "f1_": "python|python-3.x|numpy",  "answer_count": "2",  "question_scoer": "43",  "questions_creation_date": "2015-02-15T08:40:49.693Z",  "answers_score": "13",  "answers_creation_date": "2015-02-15T08:48:36.940Z",  "questions_body": "\u003cp\u003eIn Python 2 I could do the following:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np     f \u003d lambda x: x**2 seq \u003d map(f; xrange(5)) seq \u003d np.array(seq) print seq # prints: [ 0  1  4  9 16] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIn Python 3 it does not work anymore:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np     f \u003d lambda x: x**2 seq \u003d map(f; range(5)) seq \u003d np.array(seq) print(seq) # prints: \u0026lt;map object at 0x10341e310\u0026gt; \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow do I get the old behaviour (converting the \u003ccode\u003emap\u003c/code\u003e results to \u003ccode\u003enumpy\u003c/code\u003e array)?\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003eEdit\u003c/strong\u003e: As @jonrsharpe pointed out in his answer this could be fixed if I converted \u003ccode\u003eseq\u003c/code\u003e to a list first:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eseq \u003d np.array(list(seq)) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut I would prefer to avoid the extra call to \u003ccode\u003elist\u003c/code\u003e.\u003c/p\u003e",  "answers_body": "\u003cp\u003eAlthough you refer to it as \u003ccode\u003eseq\u003c/code\u003e; the \u003ccode\u003emap\u003c/code\u003e object in Python 3 is \u003cstrong\u003enot\u003c/strong\u003e a \u003cem\u003esequence\u003c/em\u003e (it\u0027s an \u003cem\u003eiterator\u003c/em\u003e; see \u003ca href\u003d\"https://docs.python.org/3/whatsnew/3.0.html#views-and-iterators-instead-of-lists\" rel\u003d\"noreferrer\"\u003ewhat\u0027s new in Python 3\u003c/a\u003e). \u003ccode\u003enumpy.array\u003c/code\u003e needs a sequence so the \u003ccode\u003elen\u003c/code\u003e can be determined and the appropriate amount of memory reserved; it won\u0027t consume an iterator. For example; the \u003ccode\u003erange\u003c/code\u003e object; which \u003cem\u003edoes\u003c/em\u003e support most sequence operations; \u003cem\u003ecan\u003c/em\u003e be passed directly;\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eseq \u003d np.array(range(5)) print(seq) # prints: [0 1 2 3 4] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eTo restore the previous behaviour; as you\u0027re aware; you can explicitly convert the \u003ccode\u003emap\u003c/code\u003e object back to a sequence (e.g. list or tuple):\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eseq \u003d np.array(list(seq))  # should probably change the name! \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHowever; as \u003ca href\u003d\"https://docs.python.org/3/whatsnew/3.0.html#views-and-iterators-instead-of-lists\" rel\u003d\"noreferrer\"\u003ethe documentation\u003c/a\u003e puts it:\u003c/p\u003e  \u003cblockquote\u003e   \u003cp\u003ea quick fix is to wrap \u003ccode\u003emap()\u003c/code\u003e in \u003ccode\u003elist()\u003c/code\u003e; e.g. \u003ccode\u003elist(map(...))\u003c/code\u003e; but a better fix is often to use a list comprehension (especially when the original code uses \u003ccode\u003elambda\u003c/code\u003e)\u003c/p\u003e \u003c/blockquote\u003e  \u003cp\u003eSo another option would be:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eseq \u003d [f(x) for x in range(5)] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eor just:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eseq \u003d [x**2 for x in range(5)] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAlternatively; actually use \u003ccode\u003enumpy\u003c/code\u003e from the start:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np     arr \u003d np.arange(5) arr **\u003d 2 print(arr) # prints [ 0  1  4  9 16] in 2.x and 3.x \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "12648624",  "f0_": "python: converting an numpy array data type from int64 to int",  "f1_": "python|types",  "answer_count": "5",  "question_scoer": "25",  "questions_creation_date": "2012-09-28T23:36:36.143Z",  "answers_score": "22",  "answers_creation_date": "2015-02-13T15:05:56.730Z",  "questions_body": "\u003cp\u003eI am somewhat new to python and I am using python modules in another program (ABAQUS). The question; however; is completely python related.\u003c/p\u003e  \u003cp\u003eIn the program; I need to create an array of integers. This array will later be used as an input in a function defined in ABAQUS. The problem is to do with the data type of the integers. In the array; the integers have data type \u0027int64\u0027. However; I am getting the following error when I input the array to the desired function:\u003c/p\u003e  \u003cblockquote\u003e   \u003cp\u003e\"Only INT; FLOAT and DOUBLE supported by the ABAQUS interface (use multiarray with typecode int if standard long is 64 bit)\"\u003c/p\u003e \u003c/blockquote\u003e  \u003cp\u003eI do not need assistance with ABAQUS. If i convert the data type to \u0027int\u0027 in python; that would suffice. I thought that I could simply use the int() function to convert the data type. This did not work. Any suggestions will be highly appreciated. Thank you all.\u003c/p\u003e",  "answers_body": "\u003cp\u003e@J.F. Sebastian\u0027s answer:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ea.astype(numpy.int32) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28207743",  "f0_": "Convert string to numpy array",  "f1_": "python|arrays|string|numpy",  "answer_count": "3",  "question_scoer": "32",  "questions_creation_date": "2015-01-29T05:44:26.370Z",  "answers_score": "26",  "answers_creation_date": "2015-01-29T05:52:26.170Z",  "questions_body": "\u003cp\u003eInput:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003emystr \u003d \u0026quot;100110\u0026quot; \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eDesired output numpy array:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003emynumpy \u003d\u003d np.array([1; 0; 0; 1; 1; 0]) \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eI have tried:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003enp.fromstring(mystr; dtype\u003dint; sep\u003d\u0027\u0027) \u003c/code\u003e\u003c/pre\u003e \u003cp\u003ebut the problem is I can\u0027t split my string to every digit of it; so numpy takes it as an one number. Any idea how to convert my string to numpy array?\u003c/p\u003e",  "answers_body": "\u003cp\u003eYou could read them as ASCII characters then subtract 48 (the ASCII value of \u003ccode\u003e0\u003c/code\u003e). This should be the fastest way for large strings.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; np.fromstring(\"100110\"; np.int8) - 48 array([1; 0; 0; 1; 1; 0]; dtype\u003dint8) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAlternatively; you could convert the string to a list of integers first:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; np.array(map(int; \"100110\")) array([1; 0; 0; 1; 1; 0]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e\u003cstrong\u003eEdit\u003c/strong\u003e: I did some quick timing and the first method is over 100x faster than converting it to a list first.\u003c/p\u003e"}
{  "id": "28176949",  "f0_": "Convert list of tuples to structured numpy array",  "f1_": "python|arrays|numpy",  "answer_count": "1",  "question_scoer": "29",  "questions_creation_date": "2015-01-27T17:58:26.803Z",  "answers_score": "39",  "answers_creation_date": "2015-01-27T18:10:29.813Z",  "questions_body": "\u003cp\u003eI have a list of \u003ccode\u003eNum_tuples\u003c/code\u003e tuples that all have the same length \u003ccode\u003eDim_tuple\u003c/code\u003e\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003exlist \u003d [tuple_1; tuple_2; ...; tuple_Num_tuples] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eFor definiteness; let\u0027s say \u003ccode\u003eNum_tuples\u003d3\u003c/code\u003e and \u003ccode\u003eDim_tuple\u003d2\u003c/code\u003e\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003exlist \u003d [(1; 1.1); (2; 1.2); (3; 1.3)] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI want to convert \u003ccode\u003exlist\u003c/code\u003e into a structured numpy array \u003ccode\u003exarr\u003c/code\u003e using a user-provided list of column names \u003ccode\u003euser_names\u003c/code\u003e and a user-provided list of variable types \u003ccode\u003euser_types\u003c/code\u003e\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003euser_names \u003d [name_1; name_2; ...; name_Dim_tuple] user_types \u003d [type_1; type_2; ...; type_Dim_tuple] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eSo in the creation of the numpy array;\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edtype \u003d [(name_1;type_1); (name_2;type_2); ...; (name_Dim_tuple; type_Dim_tuple)] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIn the case of my toy example desired end product would look something like:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003exarr[\u0027name1\u0027]\u003dnp.array([1;2;3]) xarr[\u0027name2\u0027]\u003dnp.array([1.1;1.2;1.3]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow can I slice \u003ccode\u003exlist\u003c/code\u003e to create \u003ccode\u003exarr\u003c/code\u003e without any loops?\u003c/p\u003e",  "answers_body": "\u003cp\u003eA list of tuples is the correct way of providing data to a structured array:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [273]: xlist \u003d [(1; 1.1); (2; 1.2); (3; 1.3)]  In [274]: dt\u003dnp.dtype(\u0027int;float\u0027)  In [275]: np.array(xlist;dtype\u003ddt) Out[275]:  array([(1; 1.1); (2; 1.2); (3; 1.3)];        dtype\u003d[(\u0027f0\u0027; \u0027\u0026lt;i4\u0027); (\u0027f1\u0027; \u0027\u0026lt;f8\u0027)])  In [276]: xarr \u003d np.array(xlist;dtype\u003ddt)  In [277]: xarr[\u0027f0\u0027] Out[277]: array([1; 2; 3])  In [278]: xarr[\u0027f1\u0027] Out[278]: array([ 1.1;  1.2;  1.3]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eor if the names are important:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [280]: xarr.dtype.names\u003d[\u0027name1\u0027;\u0027name2\u0027]  In [281]: xarr Out[281]:  array([(1; 1.1); (2; 1.2); (3; 1.3)];        dtype\u003d[(\u0027name1\u0027; \u0027\u0026lt;i4\u0027); (\u0027name2\u0027; \u0027\u0026lt;f8\u0027)]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e\u003ca href\u003d\"http://docs.scipy.org/doc/numpy/user/basics.rec.html#filling-structured-arrays\" rel\u003d\"noreferrer\"\u003ehttp://docs.scipy.org/doc/numpy/user/basics.rec.html#filling-structured-arrays\u003c/a\u003e\u003c/p\u003e"}
{  "id": "28207743",  "f0_": "Convert string to numpy array",  "f1_": "python|arrays|string|numpy",  "answer_count": "3",  "question_scoer": "32",  "questions_creation_date": "2015-01-29T05:44:26.370Z",  "answers_score": "43",  "answers_creation_date": "2015-01-29T05:49:58.783Z",  "questions_body": "\u003cp\u003eInput:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003emystr \u003d \u0026quot;100110\u0026quot; \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eDesired output numpy array:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003emynumpy \u003d\u003d np.array([1; 0; 0; 1; 1; 0]) \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eI have tried:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003enp.fromstring(mystr; dtype\u003dint; sep\u003d\u0027\u0027) \u003c/code\u003e\u003c/pre\u003e \u003cp\u003ebut the problem is I can\u0027t split my string to every digit of it; so numpy takes it as an one number. Any idea how to convert my string to numpy array?\u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003ccode\u003elist\u003c/code\u003e may help you do that.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np  mystr \u003d \"100110\" print np.array(list(mystr)) # [\u00271\u0027 \u00270\u0027 \u00270\u0027 \u00271\u0027 \u00271\u0027 \u00270\u0027] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIf you want to get numbers instead of string:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eprint np.array(list(mystr); dtype\u003dint) # [1 0 0 1 1 0] \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28524378",  "f0_": "Convert map object to numpy array in python 3",  "f1_": "python|python-3.x|numpy",  "answer_count": "2",  "question_scoer": "43",  "questions_creation_date": "2015-02-15T08:40:49.693Z",  "answers_score": "53",  "answers_creation_date": "2015-02-15T13:18:59.343Z",  "questions_body": "\u003cp\u003eIn Python 2 I could do the following:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np     f \u003d lambda x: x**2 seq \u003d map(f; xrange(5)) seq \u003d np.array(seq) print seq # prints: [ 0  1  4  9 16] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIn Python 3 it does not work anymore:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np     f \u003d lambda x: x**2 seq \u003d map(f; range(5)) seq \u003d np.array(seq) print(seq) # prints: \u0026lt;map object at 0x10341e310\u0026gt; \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow do I get the old behaviour (converting the \u003ccode\u003emap\u003c/code\u003e results to \u003ccode\u003enumpy\u003c/code\u003e array)?\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003eEdit\u003c/strong\u003e: As @jonrsharpe pointed out in his answer this could be fixed if I converted \u003ccode\u003eseq\u003c/code\u003e to a list first:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eseq \u003d np.array(list(seq)) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut I would prefer to avoid the extra call to \u003ccode\u003elist\u003c/code\u003e.\u003c/p\u003e",  "answers_body": "\u003cp\u003eOne more alternative; other than the valid solutions @jonrsharpe already pointed out is to use \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.fromiter.html\"\u003e\u003ccode\u003enp.fromiter\u003c/code\u003e\u003c/a\u003e:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; import numpy as np     \u0026gt;\u0026gt;\u0026gt; f \u003d lambda x: x**2 \u0026gt;\u0026gt;\u0026gt; seq \u003d map(f; range(5)) \u0026gt;\u0026gt;\u0026gt; np.fromiter(seq; dtype\u003dnp.int) array([ 0;  1;  4;  9; 16]) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "2777907",  "f0_": "python numpy roll with padding",  "f1_": "python|arrays|numpy",  "answer_count": "8",  "question_scoer": "42",  "questions_creation_date": "2010-05-06T01:39:34.510Z",  "answers_score": "5",  "answers_creation_date": "2015-02-18T19:53:10.277Z",  "questions_body": "\u003cp\u003eI\u0027d like to roll a 2D numpy in python; except that I\u0027d like pad the ends with zeros rather than roll the data as if its periodic.\u003c/p\u003e  \u003cp\u003eSpecifically; the following code\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np  x \u003d np.array([[1; 2; 3]; [4; 5; 6]])  np.roll(x; 1; axis\u003d1) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ereturns\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003earray([[3; 1; 2];[6; 4; 5]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut what I would prefer is\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003earray([[0; 1; 2]; [0; 4; 5]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI could do this with a few awkward touchups; but I\u0027m hoping that there\u0027s a way to do it with fast built-in commands.\u003c/p\u003e  \u003cp\u003eThanks\u003c/p\u003e",  "answers_body": "\u003cpre\u003e\u003ccode\u003eimport numpy as np  def shift_2d_replace(data; dx; dy; constant\u003dFalse):     \"\"\"     Shifts the array in two dimensions while setting rolled values to constant     :param data: The 2d numpy array to be shifted     :param dx: The shift in x     :param dy: The shift in y     :param constant: The constant to replace rolled values with     :return: The shifted array with \"constant\" where roll occurs     \"\"\"     shifted_data \u003d np.roll(data; dx; axis\u003d1)     if dx \u0026lt; 0:         shifted_data[:; dx:] \u003d constant     elif dx \u0026gt; 0:         shifted_data[:; 0:dx] \u003d constant      shifted_data \u003d np.roll(shifted_data; dy; axis\u003d0)     if dy \u0026lt; 0:         shifted_data[dy:; :] \u003d constant     elif dy \u0026gt; 0:         shifted_data[0:dy; :] \u003d constant     return shifted_data \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis function would work on 2D arrays and replace rolled values with a constant of your choosing.\u003c/p\u003e"}
{  "id": "8898471",  "f0_": "Concatenate two numpy arrays in the 4th dimension",  "f1_": "python|numpy",  "answer_count": "6",  "question_scoer": "29",  "questions_creation_date": "2012-01-17T16:50:08.220Z",  "answers_score": "8",  "answers_creation_date": "2015-01-26T18:48:36.207Z",  "questions_body": "\u003cp\u003eI have two numpy arrays with three dimensions (3 x 4 x 5) and I want to concatenate them so the result has four dimensions (3 x 4 x 5 x 2). In Matlab; this can be done with \u003ccode\u003ecat(4; a; b)\u003c/code\u003e; but not in Numpy.\u003c/p\u003e  \u003cp\u003eFor example:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ea \u003d ones((3;4;5)) b \u003d ones((3;4;5)) c \u003d concatenate((a;b); axis\u003d3) # error! \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eTo clarify; I wish \u003ccode\u003ec[:;:;:;0]\u003c/code\u003e and \u003ccode\u003ec[:;:;:;1]\u003c/code\u003e to correspond to the original two arrays.\u003c/p\u003e",  "answers_body": "\u003cp\u003eThe accepted answer above is great.  But I\u0027ll add the following because I\u0027m a math dork and it\u0027s a nice use of the fact that \u003ccode\u003ea.shape\u003c/code\u003e is \u003ccode\u003ea.T.shape[::-1]\u003c/code\u003e...i.e. taking a transpose reverses the order of the indices of a numpy array.  So if you have your building blocks in an array called blocks; then the solution above is:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enew \u003d np.concatenate([block[...; np.newaxis] for block in blocks];                      axis\u003dlen(blocks[0].shape)) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut you could also do\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enew2 \u003d np.array([block.T for block in blocks]).T \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ewhich I think reads more cleanly.  It\u0027s worth noting that the already-accepted answer runs more quickly:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e%%timeit new \u003d np.concatenate([block[...; np.newaxis] for block in blocks];                      axis\u003dlen(blocks[0].shape)) 1000 loops; best of 3: 321 µs per loop \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ewhile\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e%%timeit new2 \u003d np.array([block.T for block in blocks]).T 1000 loops; best of 3: 407 µs per loop \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28157976",  "f0_": "Importing opencv and getting numpy.core.multiarray failed to import",  "f1_": "python|opencv|numpy",  "answer_count": "7",  "question_scoer": "19",  "questions_creation_date": "2015-01-26T20:14:15.083Z",  "answers_score": "18",  "answers_creation_date": "2015-01-27T04:58:49.167Z",  "questions_body": "\u003cp\u003eTrying to install OpenCV and running into an issue where attempting to import cv2 results in this output -\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e    RuntimeError: module compiled against API version 9 but this version of numpy is 7  Traceback (most recent call last): File \"\u0026lt;pyshell#4\u0026gt;\"; line 1; in \u0026lt;module\u0026gt; import cv2 ImportError: numpy.core.multiarray failed to import \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI\u0027m running on Windows 7 x64; Python v 2.7.9 Thanks!\u003c/p\u003e",  "answers_body": "\u003cp\u003eThe error is telling you that you have an out of date version of numpy. If you used \u003ccode\u003epip\u003c/code\u003e to install things you can simply run pip install numpy -U; or download the appropriate version from their website.\u003c/p\u003e"}
{  "id": "28125265",  "f0_": "concatenate numpy arrays which are elements of a list",  "f1_": "python|arrays|list|numpy",  "answer_count": "2",  "question_scoer": "39",  "questions_creation_date": "2015-01-24T12:02:31.350Z",  "answers_score": "24",  "answers_creation_date": "2015-01-24T17:28:18.960Z",  "questions_body": "\u003cp\u003eI have a list containing numpy arrays something like L\u003d[a;b;c] where a; b and c are numpy arrays with sizes N_a in T; N_b in T and N_c in T.\u003cbr\u003e I want to row-wise concatenate a; b and c and get a numpy array with shape (N_a+N_b+N_c; T). Clearly one solution is run a for loop and use numpy.concatenate; but is there any pythonic way to do this?\u003c/p\u003e  \u003cp\u003eThanks\u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003ccode\u003ehelp(\u0027concatenate\u0027\u003c/code\u003e has this signature:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003econcatenate(...)     concatenate((a1; a2; ...); axis\u003d0)      Join a sequence of arrays together. \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e\u003ccode\u003e(a1; a2; ...)\u003c/code\u003e looks like your list; doesn\u0027t it?  And the default axis is the one you want to join.  So lets try it:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [149]: L \u003d [np.ones((3;2)); np.zeros((2;2)); np.ones((4;2))]  In [150]: np.concatenate(L) Out[150]:  array([[ 1.;  1.];        [ 1.;  1.];        [ 1.;  1.];        [ 0.;  0.];        [ 0.;  0.];        [ 1.;  1.];        [ 1.;  1.];        [ 1.;  1.];        [ 1.;  1.]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e\u003ccode\u003evstack\u003c/code\u003e also does this; but look at its code:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef vstack(tup):     return np.concatenate([atleast_2d(_m) for _m in tup]; 0) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAll it does extra is make sure that the component arrays have 2 dimensions; which yours do.\u003c/p\u003e"}
{  "id": "28327101",  "f0_": "Can\u0027t call strftime on numpy.datetime64; no definition",  "f1_": "python|numpy",  "answer_count": "6",  "question_scoer": "31",  "questions_creation_date": "2015-02-04T16:59:13.470Z",  "answers_score": "37",  "answers_creation_date": "2015-02-04T17:28:52.753Z",  "questions_body": "\u003cp\u003eI have a datetime64 \u003ccode\u003et\u003c/code\u003e that I\u0027d like to represent as a string.\u003c/p\u003e  \u003cp\u003eWhen I call strftime like this \u003ccode\u003et.strftime(\u0027%Y.%m.%d\u0027)\u003c/code\u003e I get this error:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eAttributeError: \u0027numpy.datetime64\u0027 object has no attribute \u0027strftime\u0027 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eWhat am I missing? I am using Python 3.4.2 and Numpy 1.9.1\u003c/p\u003e",  "answers_body": "\u003cp\u003eUse this code:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport pandas as pd  t\u003d pd.to_datetime(str(date))  timestring \u003d t.strftime(\u0027%Y.%m.%d\u0027) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "13370570",  "f0_": "Elegant grid search in python/numpy",  "f1_": "python|numpy",  "answer_count": "4",  "question_scoer": "31",  "questions_creation_date": "2012-11-13T23:18:17.383Z",  "answers_score": "43",  "answers_creation_date": "2015-01-22T15:16:52.163Z",  "questions_body": "\u003cp\u003eI have a function that has a bunch of parameters. Rather than setting all of the parameters manually; I want to perform a grid search. I have a list of possible values for each parameter. For every possible combination of parameters; I want to run my function which reports the performance of my algorithm on those parameters. I want to store the results of this in a many-dimensional matrix; so that afterwords I can just find the index of the maximum performance; which would in turn give me the best parameters. Here is how the code is written now:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eparam1_list \u003d [p11; p12; p13;...] param2_list \u003d [p21; p22; p23;...] # not necessarily the same number of values ...  results_size \u003d (len(param1_list); len(param2_list);...) results \u003d np.zeros(results_size; dtype \u003d np.float)  for param1_idx in range(len(param1_list)):   for param2_idx in range(len(param2_list)):     ...     param1 \u003d param1_list[param1_idx]     param2 \u003d param2_list[param2_idx]     ...     results[param1_idx; param2_idx; ...] \u003d my_func(param1; param2; ...)  max_index \u003d np.argmax(results) # indices of best parameters! \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI want to keep the first part; where I define the lists as-is; since I want to easily be able to manipulate the values over which I search.\u003c/p\u003e  \u003cp\u003eI also want to end up with the results matrix as is; since I will be visualizing how changing different parameters affects the performance of the algorithm.\u003c/p\u003e  \u003cp\u003eThe bit in the middle; though; is quite repetitive and bulky (especially because I have lots of parameters; and I might want to add or remove parameters); and I feel like there should be a more succinct/elegant way to initialize the results matrix; iterate over all of the indices; and set the appropriate parameters.\u003c/p\u003e  \u003cp\u003eSo; is there?\u003c/p\u003e",  "answers_body": "\u003cp\u003eYou can use the ParameterGrid from the sklearn module\u003c/p\u003e  \u003cp\u003e\u003ca href\u003d\"http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.ParameterGrid.html\" rel\u003d\"noreferrer\"\u003ehttp://scikit-learn.org/stable/modules/generated/sklearn.grid_search.ParameterGrid.html\u003c/a\u003e\u003c/p\u003e  \u003cp\u003eExample\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003efrom sklearn.grid_search import ParameterGrid param_grid \u003d {\u0027param1\u0027: [value1; value2; value3]; \u0027paramN\u0027 : [value1; value2; valueM]}  grid \u003d ParameterGrid(param_grid)  for params in grid:     your_function(params[\u0027param1\u0027]; params[\u0027param2\u0027]) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28430904",  "f0_": "Set numpy array elements to zero if they are above a specific threshold",  "f1_": "python|arrays|numpy",  "answer_count": "4",  "question_scoer": "67",  "questions_creation_date": "2015-02-10T11:48:29.720Z",  "answers_score": "59",  "answers_creation_date": "2015-02-10T11:57:20.107Z",  "questions_body": "\u003cp\u003eSay; I have a numpy array consists of \u003ccode\u003e10\u003c/code\u003e elements; for example:\u003c/p\u003e  \u003cp\u003e\u003ccode\u003ea \u003d np.array([2; 23; 15; 7; 9; 11; 17; 19; 5; 3])\u003c/code\u003e\u003c/p\u003e  \u003cp\u003eNow I want to efficiently set all \u003ccode\u003ea\u003c/code\u003e values higher than \u003ccode\u003e10\u003c/code\u003e to \u003ccode\u003e0\u003c/code\u003e; so I\u0027ll get:\u003c/p\u003e  \u003cp\u003e\u003ccode\u003e[2; 0; 0; 7; 9; 0; 0; 0; 5; 3]\u003c/code\u003e\u003c/p\u003e  \u003cp\u003eBecause I currently use a \u003ccode\u003efor\u003c/code\u003e loop; which is very slow:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e# Zero values below \"threshold value\". def flat_values(sig; tv):     \"\"\"     :param sig: signal.     :param tv: threshold value.     :return:     \"\"\"     for i in np.arange(np.size(sig)):         if sig[i] \u0026lt; tv:             sig[i] \u003d 0     return sig \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow can I achieve that in the most efficient way; having in mind big arrays of; say; \u003ccode\u003e10^6\u003c/code\u003e elements?\u003c/p\u003e",  "answers_body": "\u003cp\u003eGenerally; list comprehensions are faster than \u003ccode\u003efor\u003c/code\u003e loops in python (because python knows that it doesn\u0027t need to care for a lot of things that might happen in a regular \u003ccode\u003efor\u003c/code\u003e loop):\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ea \u003d [0 if a_ \u0026gt; thresh else a_ for a_ in a] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut; as @unutbu correctly \u003ca href\u003d\"https://stackoverflow.com/a/28430952/4433386\"\u003epointed out\u003c/a\u003e; numpy allows list indexing; and element-wise comparison giving you index lists; so:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003esuper_threshold_indices \u003d a \u0026gt; thresh a[super_threshold_indices] \u003d 0 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ewould be even faster.\u003c/p\u003e  \u003cp\u003eGenerally; when applying methods on vectors of data; have a look at \u003ccode\u003enumpy.ufuncs\u003c/code\u003e; which often perform much better than python functions that you map using any native mechanism.\u003c/p\u003e"}
{  "id": "28363447",  "f0_": "What are the advantages of using numpy.identity over numpy.eye?",  "f1_": "python|arrays|performance|numpy",  "answer_count": "3",  "question_scoer": "58",  "questions_creation_date": "2015-02-06T10:19:23.673Z",  "answers_score": "80",  "answers_creation_date": "2015-02-06T10:30:52.810Z",  "questions_body": "\u003cp\u003eHaving looked over the man pages for \u003ccode\u003enumpy\u003c/code\u003e\u0027s \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003eeye\u003c/code\u003e\u003c/a\u003e and \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.identity.html\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003eidentity\u003c/code\u003e\u003c/a\u003e; I\u0027d assumed that \u003ccode\u003eidentity\u003c/code\u003e was a special case of \u003ccode\u003eeye\u003c/code\u003e; since it has fewer options (e.g. \u003ccode\u003eeye\u003c/code\u003e can fill shifted diagonals; \u003ccode\u003eidentity\u003c/code\u003e cannot); but could plausibly run more quickly. However; this isn\u0027t the case on either small or large arrays:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; np.identity(3)                                                   array([[ 1.;  0.;  0.];        [ 0.;  1.;  0.];        [ 0.;  0.;  1.]]) \u0026gt;\u0026gt;\u0026gt; np.eye(3)                                                        array([[ 1.;  0.;  0.];        [ 0.;  1.;  0.];        [ 0.;  0.;  1.]]) \u0026gt;\u0026gt;\u0026gt; timeit.timeit(\u0026quot;import numpy; numpy.identity(3)\u0026quot;; number \u003d 10000) 0.05699801445007324 \u0026gt;\u0026gt;\u0026gt; timeit.timeit(\u0026quot;import numpy; numpy.eye(3)\u0026quot;; number \u003d 10000)      0.03787708282470703 \u0026gt;\u0026gt;\u0026gt; timeit.timeit(\u0026quot;import numpy\u0026quot;; number \u003d 10000)                    0.00960087776184082 \u0026gt;\u0026gt;\u0026gt; timeit.timeit(\u0026quot;import numpy; numpy.identity(1000)\u0026quot;; number \u003d 10000) 11.379066944122314 \u0026gt;\u0026gt;\u0026gt; timeit.timeit(\u0026quot;import numpy; numpy.eye(1000)\u0026quot;; number \u003d 10000)      11.247124910354614 \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eWhat; then; is the advantage of using \u003ccode\u003eidentity\u003c/code\u003e over \u003ccode\u003eeye\u003c/code\u003e?\u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003ccode\u003eidentity\u003c/code\u003e just calls \u003ccode\u003eeye\u003c/code\u003e so there is no difference in how the arrays are constructed. Here\u0027s the code for \u003ca href\u003d\"https://github.com/numpy/numpy/blob/v1.9.1/numpy/core/numeric.py#L2125\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003eidentity\u003c/code\u003e\u003c/a\u003e: \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef identity(n; dtype\u003dNone):     from numpy import eye     return eye(n; dtype\u003ddtype) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAs you say; the main difference is that with \u003ccode\u003eeye\u003c/code\u003e the diagonal can may be offset; whereas \u003ccode\u003eidentity\u003c/code\u003e only fills the main diagonal. \u003c/p\u003e  \u003cp\u003eSince the identity matrix is such a common construct in mathematics; it seems the main advantage of using \u003ccode\u003eidentity\u003c/code\u003e is for its name alone.\u003c/p\u003e"}
{  "id": "28364708",  "f0_": "Convert tuple to numpy ndarray",  "f1_": "python|arrays|numpy|raspberry-pi|tuples",  "answer_count": "1",  "question_scoer": "-3",  "questions_creation_date": "2015-02-06T11:25:15.380Z",  "answers_score": "0",  "answers_creation_date": "2015-02-06T12:02:33.997Z",  "questions_body": "\u003cp\u003eI\u0027m developping a small script in image treatment in python which running on raspberry PI. I have a problem about the variable type. I have two functions. The first one is a function that converts an RGB image to binary; which works:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimg_bw \u003d cv2.threshold(img_filtered;127;255;cv2.THRESH_BINARY) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThe second function allows me to clean the pixel less than 300px \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimg_morph \u003d morphology.binary_opening(img_bw;ones((9;5));iterations\u003d2) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThe result when I try to execute:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e*input \u003d numpy.asarray(input) File \"/usr/lib/pymodules/python2.7/numpy/core/numeric.py\"; line 235; in   asarray return array(a; dtype; copy\u003dFalse; order\u003dorder)  ValueError: setting an array element with a sequence.* \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAccording to some research in the forum; I understood the problem is about the type of the variable. The type of \u003ccode\u003eimg_bw\u003c/code\u003e is a \u003ccode\u003etuple\u003c/code\u003e type and the second function needs a variable of type \u003ccode\u003endarray\u003c/code\u003e. I didn\u0027t find a correct syntax that allow me to convert \u003ccode\u003etuple\u003c/code\u003e to \u003ccode\u003endarray\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003eCan anyone point me in the right direction?\u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003ccode\u003ecv2.threshold\u003c/code\u003e itself retuns a tuple; that you can properly assign as follows\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eretval; img_bw \u003d cv2.threshold(img_filtered;127;255;cv2.THRESH_BINARY) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eyour original code \u003ccode\u003eimg_bw \u003d cv2.threshold(img_filtered;127;255;cv2.THRESH_BINARY)\u003c/code\u003e assigns the tuple to \u003ccode\u003eimg_bw\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003eSee the documentation (\u003ca href\u003d\"http://docs.opencv.org/trunk/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html\" rel\u003d\"nofollow\"\u003ehttp://docs.opencv.org/trunk/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html\u003c/a\u003e)\u003c/p\u003e"}
{  "id": "16856470",  "f0_": "Is there a MATLAB accumarray equivalent in numpy?",  "f1_": "python|numpy|accumulator",  "answer_count": "7",  "question_scoer": "17",  "questions_creation_date": "2013-05-31T11:41:14.757Z",  "answers_score": "8",  "answers_creation_date": "2015-02-10T20:18:38.653Z",  "questions_body": "\u003cp\u003eI\u0027m looking for a fast solution to MATLAB\u0027s \u003ca href\u003d\"http://www.mathworks.com/help/matlab/ref/accumarray.html\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003eaccumarray\u003c/code\u003e\u003c/a\u003e in numpy. The \u003ccode\u003eaccumarray\u003c/code\u003e accumulates the elements of an array which belong to the same index. An example:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ea \u003d np.arange(1;11) # array([ 1;  2;  3;  4;  5;  6;  7;  8;  9; 10]) accmap \u003d np.array([0;1;0;0;0;1;1;2;2;1]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eResult should be \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003earray([13; 25; 17]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e\u003cstrong\u003eWhat I\u0027ve done so far:\u003c/strong\u003e I\u0027ve tried the \u003ccode\u003eaccum\u003c/code\u003e function in the \u003ca href\u003d\"http://www.scipy.org/Cookbook/AccumarrayLike\" rel\u003d\"noreferrer\"\u003erecipe here\u003c/a\u003e which works fine but is slow.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eaccmap \u003d np.repeat(np.arange(1000); 20) a \u003d np.random.randn(accmap.size) %timeit accum(accmap; a; np.sum) # 1 loops; best of 3: 293 ms per loop \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThen I tried to use the \u003ca href\u003d\"http://mldesign.net/blog/2013/02/18/speedy-numpy-replacement-for-matlab-accumarray/\" rel\u003d\"noreferrer\"\u003esolution here\u003c/a\u003e which is supposed to work faster but it doesn\u0027t work correctly:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eaccum_np(accmap; a) # array([  1.;   2.;  12.;  13.;  17.;  10.]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIs there a built-in numpy function that can do accumulation like this? Or any other recommendations?\u003c/p\u003e",  "answers_body": "\u003cp\u003eLate to the party; but...\u003c/p\u003e  \u003cp\u003eAs @Jamie says; for the case of summing; \u003ccode\u003enp.bincount\u003c/code\u003e is fast and simple. However in the more general case; for other \u003ccode\u003eufuncs\u003c/code\u003e such as \u003ccode\u003emaximum\u003c/code\u003e; you can use the \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.at.html\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003enp.ufunc.at\u003c/code\u003e\u003c/a\u003e method.\u003c/p\u003e  \u003cp\u003eI\u0027ve put together \u003cs\u003e\u003ca href\u003d\"https://gist.github.com/d1manson/5f78561c0f52d3073fe8\" rel\u003d\"noreferrer\"\u003ea gist\u003c/a\u003e\u003c/s\u003e[see link below instead] which encapsulates this in a Matlab-like interface.  It also takes advantage of the repeated indexing rules to provide a \u003ccode\u003e\u0027last\u0027\u003c/code\u003e and \u003ccode\u003e\u0027first\u0027\u003c/code\u003e function; and unlike Matlab; \u003ccode\u003e\u0027mean\u0027\u003c/code\u003e is sensibly optimized (calling \u003ccode\u003eaccumarray\u003c/code\u003e with \u003ccode\u003e@mean\u003c/code\u003e in Matlab is really slow because it runs a non-builtin function for every single group; which is stupid).\u003c/p\u003e  \u003cp\u003eBe warned that I haven\u0027t particularly tested the gist; but will hopefully update it in future with extra features and bugfixes.\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003eUpdate May/June-2015:\u003c/strong\u003e I have reworked my implementation - it is now available as part of \u003ca href\u003d\"https://github.com/ml31415/numpy-groupies/\" rel\u003d\"noreferrer\"\u003eml31415/numpy-groupies\u003c/a\u003e and available on PyPi (\u003ccode\u003epip install numpy-groupies\u003c/code\u003e). Benchmarks are as follows (see github repo for up-to-date values)...\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003efunction  pure-py  np-grouploop   np-ufuncat np-optimised    pandas        ratio      std  1737.8ms       171.8ms     no-impl       7.0ms    no-impl   247.1: 24.4:  -  : 1.0 :  -        all  1280.8ms        62.2ms      41.8ms       6.6ms    550.7ms   193.5: 9.4 : 6.3 : 1.0 : 83.2      min  1358.7ms        59.6ms      42.6ms      42.7ms     24.5ms    55.4: 2.4 : 1.7 : 1.7 : 1.0       max  1538.3ms        55.9ms      38.8ms      37.5ms     18.8ms    81.9: 3.0 : 2.1 : 2.0 : 1.0       sum  1532.8ms        62.6ms      40.6ms       1.9ms     20.4ms   808.5: 33.0: 21.4: 1.0 : 10.7      var  1756.8ms       146.2ms     no-impl       6.3ms    no-impl   279.1: 23.2:  -  : 1.0 :  -       prod  1448.8ms        55.2ms      39.9ms      38.7ms     20.2ms    71.7: 2.7 : 2.0 : 1.9 : 1.0       any  1399.5ms        69.1ms      41.1ms       5.7ms    558.8ms   246.2: 12.2: 7.2 : 1.0 : 98.3     mean  1321.3ms        88.3ms     no-impl       4.0ms     20.9ms   327.6: 21.9:  -  : 1.0 : 5.2  Python 2.7.9; Numpy 1.9.2; Win7 Core i7. \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHere we are using \u003ccode\u003e100;000\u003c/code\u003e indices uniformly picked from \u003ccode\u003e[0; 1000)\u003c/code\u003e. Specifically; about 25% of the values are \u003ccode\u003e0\u003c/code\u003e (for use with bool operations); the remainder are uniformly distribuited on \u003ccode\u003e[-50;25)\u003c/code\u003e. Timings are shown for 10 repeats.\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cem\u003epurepy\u003c/em\u003e - uses nothing but pure python; relying partly on \u003ccode\u003eitertools.groupby\u003c/code\u003e.   \u003c/li\u003e \u003cli\u003e\u003cem\u003enp-grouploop\u003c/em\u003e - uses \u003ccode\u003enumpy\u003c/code\u003e to sort values based on \u003ccode\u003eidx\u003c/code\u003e; then uses \u003ccode\u003esplit\u003c/code\u003e to create separate arrays; and then loops over these arrays; running the relevant \u003ccode\u003enumpy\u003c/code\u003e function for each array.\u003c/li\u003e \u003cli\u003e\u003cem\u003enp-ufuncat\u003c/em\u003e - uses the \u003ccode\u003enumpy\u003c/code\u003e \u003ccode\u003eufunc.at\u003c/code\u003e method; which is slower than it ought to be - as disuccsed in \u003ca href\u003d\"https://github.com/numpy/numpy/issues/5922\" rel\u003d\"noreferrer\"\u003ean issue\u003c/a\u003e I created on numpy\u0027s github repo.\u003c/li\u003e \u003cli\u003e\u003cem\u003enp-optimisied\u003c/em\u003e - uses custom \u003ccode\u003enumpy\u003c/code\u003e indexing/other tricks to beat the above two implementations (except for \u003ccode\u003emin max prod\u003c/code\u003e which rely on \u003ccode\u003eufunc.at\u003c/code\u003e).\u003c/li\u003e \u003cli\u003e\u003cem\u003epandas\u003c/em\u003e - \u003ccode\u003epd.DataFrame({\u0027idx\u0027:idx; \u0027vals\u0027:vals}).groupby(\u0027idx\u0027).sum()\u003c/code\u003e etc.\u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eNote that some of the \u003ccode\u003eno-impl\u003c/code\u003es may be unwarranted; but I haven\u0027t bothered to get them working yet.  \u003c/p\u003e  \u003cp\u003eAs explained on github; \u003ccode\u003eaccumarray\u003c/code\u003e now supports \u003ccode\u003enan\u003c/code\u003e-prefixed functions (e.g. \u003ccode\u003enansum\u003c/code\u003e) as well as; \u003ccode\u003esort\u003c/code\u003e; \u003ccode\u003ersort\u003c/code\u003e; and \u003ccode\u003earray\u003c/code\u003e.  It also works with multidimensional indexing.\u003c/p\u003e"}
{  "id": "28563711",  "f0_": "Make a numpy array monotonic without a Python loop",  "f1_": "python|arrays|numpy|vectorization",  "answer_count": "1",  "question_scoer": "24",  "questions_creation_date": "2015-02-17T14:30:04.620Z",  "answers_score": "34",  "answers_creation_date": "2015-02-17T14:39:43.987Z",  "questions_body": "\u003cp\u003eI have a 1D array of values which is supposed to be monotonic (let\u0027s say decreasing); but there are random regions where the value increases with index.\u003c/p\u003e  \u003cp\u003eI need an array where each region is replaced with a value directly preceding it; so that the resulting array is sorted.\u003c/p\u003e  \u003cp\u003eSo if given array is:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ea \u003d np.array([10.0; 9.5; 8.0; 7.2; 7.8; 8.0; 7.0; 5.0; 3.0; 2.5; 3.0; 2.0]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI want the result to be\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eb \u003d np.array([10.0; 9.5; 8.0; 7.2; 7.2; 7.2; 7.0; 5.0; 3.0; 2.5; 2.5; 2.0]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHere\u0027s a graphical representation:\u003c/p\u003e  \u003cp\u003e\u003cimg src\u003d\"https://i.stack.imgur.com/BPfzu.png\" alt\u003d\"example\"\u003e\u003c/p\u003e  \u003cp\u003eI know how to achieve it with a Python loop; but is there a way to do this with NumPy machinery?\u003c/p\u003e  \u003cp\u003ePython code for clarity:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eb \u003d np.array(a) for i in range(1; b.size):     if b[i] \u0026gt; b[i-1]:         b[i] \u003d b[i-1] \u003c/code\u003e\u003c/pre\u003e",  "answers_body": "\u003cp\u003eYou can use \u003ccode\u003enp.minimum.accumulate\u003c/code\u003e to collect the minimum values as you move through the array:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; np.minimum.accumulate(a) array([ 10. ;   9.5;   8. ;   7.2;   7.2;   7.2;   7. ;   5. ;   3. ;          2.5;   2.5;   2. ]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAt each element in the array; this function returns the minimum value seen so far.\u003c/p\u003e  \u003cp\u003eIf you wanted an array to be monotonic increasing; you could use \u003ccode\u003enp.maximum.accumulate\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003eMany other universal functions in NumPy have an \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.accumulate.html\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003eaccumulate\u003c/code\u003e\u003c/a\u003e method to simulate looping through an array; applying the function to each element and collecting the returned values into an array of the same size.\u003c/p\u003e"}
{  "id": "28697993",  "f0_": "numpy: what is the logic of the argmin() and argmax() functions?",  "f1_": "python|arrays|numpy|argmax",  "answer_count": "5",  "question_scoer": "31",  "questions_creation_date": "2015-02-24T14:10:57.290Z",  "answers_score": "55",  "answers_creation_date": "2015-02-24T14:22:47.933Z",  "questions_body": "\u003cp\u003eI can not understand the output of \u003ccode\u003eargmax\u003c/code\u003e and \u003ccode\u003eargmin\u003c/code\u003e when use with the axis parameter. For example:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; a \u003d np.array([[1;2;4;7]; [9;88;6;45]; [9;76;3;4]]) \u0026gt;\u0026gt;\u0026gt; a array([[ 1;  2;  4;  7];        [ 9; 88;  6; 45];        [ 9; 76;  3;  4]]) \u0026gt;\u0026gt;\u0026gt; a.shape (3; 4) \u0026gt;\u0026gt;\u0026gt; a.size 12 \u0026gt;\u0026gt;\u0026gt; np.argmax(a) 5 \u0026gt;\u0026gt;\u0026gt; np.argmax(a;axis\u003d0) array([1; 1; 1; 1]) \u0026gt;\u0026gt;\u0026gt; np.argmax(a;axis\u003d1) array([3; 1; 1]) \u0026gt;\u0026gt;\u0026gt; np.argmin(a) 0 \u0026gt;\u0026gt;\u0026gt; np.argmin(a;axis\u003d0) array([0; 0; 2; 2]) \u0026gt;\u0026gt;\u0026gt; np.argmin(a;axis\u003d1) array([0; 2; 2]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAs you can see; the maximum value is the point (1;1) and the minimum one is the point (0;0). So in my logic when I run:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003ccode\u003enp.argmin(a;axis\u003d0)\u003c/code\u003e I expected \u003ccode\u003earray([0;0;0;0])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmin(a;axis\u003d1)\u003c/code\u003e I expected \u003ccode\u003earray([0;0;0])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmax(a;axis\u003d0)\u003c/code\u003e I expected \u003ccode\u003earray([1;1;1;1])\u003c/code\u003e \u003c/li\u003e \u003cli\u003e\u003ccode\u003enp.argmax(a;axis\u003d1)\u003c/code\u003e I expected \u003ccode\u003earray([1;1;1])\u003c/code\u003e \u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eWhat is wrong with my understanding of things?\u003c/p\u003e",  "answers_body": "\u003cp\u003eBy adding the \u003ccode\u003eaxis\u003c/code\u003e argument; NumPy looks at the rows and columns individually. When it\u0027s not given; the array \u003ccode\u003ea\u003c/code\u003e is flattened into a single 1D array.\u003c/p\u003e  \u003cp\u003e\u003ccode\u003eaxis\u003d0\u003c/code\u003e means that the operation is performed \u003cem\u003edown\u003c/em\u003e the columns of a 2D array \u003ccode\u003ea\u003c/code\u003e in turn.\u003c/p\u003e  \u003cp\u003eFor example \u003ccode\u003enp.argmin(a; axis\u003d0)\u003c/code\u003e returns the index of the minimum value in each of the four columns. The minimum value in each column is shown in   \u003cstrong\u003ebold\u003c/strong\u003e below:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u003e\u003e\u003e a array([[ \u003cb\u003e1\u003c/b\u003e;  \u003cb\u003e2\u003c/b\u003e;  4;  7];  # 0        [ 9; 88;  6; 45];  # 1        [ 9; 76;  \u003cb\u003e3\u003c/b\u003e;  \u003cb\u003e4\u003c/b\u003e]]) # 2  \u003e\u003e\u003e np.argmin(a; axis\u003d0) array([0; 0; 2; 2]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eOn the other hand; \u003ccode\u003eaxis\u003d1\u003c/code\u003e means that the operation is performed \u003cem\u003eacross\u003c/em\u003e the rows of \u003ccode\u003ea\u003c/code\u003e. \u003c/p\u003e  \u003cp\u003eThat means \u003ccode\u003enp.argmin(a; axis\u003d1)\u003c/code\u003e returns \u003ccode\u003e[0; 2; 2]\u003c/code\u003e because \u003ccode\u003ea\u003c/code\u003e has three rows. The index of the minimum value in the first row is 0; the index of the minimum value of the second and third rows is 2:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e\u003e\u003e\u003e a #        0   1   2   3 array([[ \u003cb\u003e1\u003c/b\u003e;  2;  4;  7];        [ 9; 88;  \u003cb\u003e6\u003c/b\u003e; 45];        [ 9; 76;  \u003cb\u003e3\u003c/b\u003e;  4]])  \u003e\u003e\u003e np.argmin(a; axis\u003d1) array([0; 2; 2]) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28430904",  "f0_": "Set numpy array elements to zero if they are above a specific threshold",  "f1_": "python|arrays|numpy",  "answer_count": "4",  "question_scoer": "67",  "questions_creation_date": "2015-02-10T11:48:29.720Z",  "answers_score": "145",  "answers_creation_date": "2015-02-10T11:50:05.330Z",  "questions_body": "\u003cp\u003eSay; I have a numpy array consists of \u003ccode\u003e10\u003c/code\u003e elements; for example:\u003c/p\u003e  \u003cp\u003e\u003ccode\u003ea \u003d np.array([2; 23; 15; 7; 9; 11; 17; 19; 5; 3])\u003c/code\u003e\u003c/p\u003e  \u003cp\u003eNow I want to efficiently set all \u003ccode\u003ea\u003c/code\u003e values higher than \u003ccode\u003e10\u003c/code\u003e to \u003ccode\u003e0\u003c/code\u003e; so I\u0027ll get:\u003c/p\u003e  \u003cp\u003e\u003ccode\u003e[2; 0; 0; 7; 9; 0; 0; 0; 5; 3]\u003c/code\u003e\u003c/p\u003e  \u003cp\u003eBecause I currently use a \u003ccode\u003efor\u003c/code\u003e loop; which is very slow:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e# Zero values below \"threshold value\". def flat_values(sig; tv):     \"\"\"     :param sig: signal.     :param tv: threshold value.     :return:     \"\"\"     for i in np.arange(np.size(sig)):         if sig[i] \u0026lt; tv:             sig[i] \u003d 0     return sig \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow can I achieve that in the most efficient way; having in mind big arrays of; say; \u003ccode\u003e10^6\u003c/code\u003e elements?\u003c/p\u003e",  "answers_body": "\u003cpre\u003e\u003ccode\u003eIn [7]: a \u003d np.array([2; 23; 15; 7; 9; 11; 17; 19; 5; 3])  In [8]: a[a \u0026gt; 10] \u003d 0  In [9]: a Out[9]: array([2; 0; 0; 7; 9; 0; 0; 0; 5; 3]) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28269379",  "f0_": "Curve curvature in numpy",  "f1_": "python|numpy",  "answer_count": "1",  "question_scoer": "22",  "questions_creation_date": "2015-02-01T23:55:51.400Z",  "answers_score": "49",  "answers_creation_date": "2015-02-02T02:34:13.743Z",  "questions_body": "\u003cp\u003eI am measuring x;y coordinates (in cm) of an object with a special camera in fixed time intervals of 1s. I have the data in a numpy array:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ea \u003d np.array([ [  0.  ;   0.  ];[  0.3 ;   0.  ];[  1.25;  -0.1 ];[  2.1 ;  -0.9 ];[  2.85;  -2.3 ];[  3.8 ;  -3.95];[  5.  ;  -5.75];[  6.4 ;  -7.8 ];[  8.05;  -9.9 ];[  9.9 ; -11.6 ];[ 12.05; -12.85];[ 14.25; -13.7 ];[ 16.5 ; -13.8 ];[ 19.25; -13.35];[ 21.3 ; -12.2 ];[ 22.8 ; -10.5 ];[ 23.55;  -8.15];[ 22.95;  -6.1 ];[ 21.35;  -3.95];[ 19.1 ;  -1.9 ]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAnd the curve looks like this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eplt.scatter(a[:;0]; a[:;1]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e\u003cimg src\u003d\"https://i.stack.imgur.com/KBjxL.png\" alt\u003d\"enter image description here\"\u003e\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003eQuestion:\u003c/strong\u003e\u003c/p\u003e  \u003cp\u003eHow can I calculate the tangential and the radial aceleration vectors at each point? I found some formulas that might be relevant:\u003c/p\u003e  \u003cp\u003e\u003cimg src\u003d\"https://i.stack.imgur.com/Xby4N.png\" alt\u003d\"enter image description here\"\u003e\u003c/p\u003e  \u003cp\u003eI am able to easily calculate the \u003ccode\u003evx\u003c/code\u003e and the \u003ccode\u003evy\u003c/code\u003e projections with \u003ccode\u003enp.diff(a; axis\u003d0)\u003c/code\u003e but I am a numpy/python noob and it is way over my head to continue. If I could calculate the curvature at each point; also my problem would be solved. Can somebody help?\u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003cstrong\u003eEDIT\u003c/strong\u003e: I put together this answer off and on over a couple of hours; so I missed your latest edits indicating that you only needed curvature. Hopefully; this answer will be helpful regardless.\u003c/p\u003e  \u003cp\u003eOther than doing some curve-fitting; our method of approximating derivatives is via \u003ca href\u003d\"http://en.wikipedia.org/wiki/Finite_difference\"\u003efinite differences\u003c/a\u003e. Thankfully; \u003ccode\u003enumpy\u003c/code\u003e has a \u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.gradient.html\"\u003e\u003ccode\u003egradient\u003c/code\u003e\u003c/a\u003e method that does these difference calculations for us; taking care of the details of averaging previous and next slopes for each interior point and leaving each endpoint alone; etc.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np  a \u003d np.array([ [  0.  ;   0.  ];[  0.3 ;   0.  ];[  1.25;  -0.1 ];               [  2.1 ;  -0.9 ];[  2.85;  -2.3 ];[  3.8 ;  -3.95];               [  5.  ;  -5.75];[  6.4 ;  -7.8 ];[  8.05;  -9.9 ];               [  9.9 ; -11.6 ];[ 12.05; -12.85];[ 14.25; -13.7 ];               [ 16.5 ; -13.8 ];[ 19.25; -13.35];[ 21.3 ; -12.2 ];               [ 22.8 ; -10.5 ];[ 23.55;  -8.15];[ 22.95;  -6.1 ];               [ 21.35;  -3.95];[ 19.1 ;  -1.9 ]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eNow; we compute the derivatives of each variable and put them together (for some reason; if we just call \u003ccode\u003enp.gradient(a)\u003c/code\u003e; we get a list of arrays...not sure off the top of my head what\u0027s going on there; but I\u0027ll just work around it for now):\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edx_dt \u003d np.gradient(a[:; 0]) dy_dt \u003d np.gradient(a[:; 1]) velocity \u003d np.array([ [dx_dt[i]; dy_dt[i]] for i in range(dx_dt.size)]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis gives us the following vector for \u003ccode\u003evelocity\u003c/code\u003e:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003earray([[ 0.3  ;  0.   ];        [ 0.625; -0.05 ];        [ 0.9  ; -0.45 ];        [ 0.8  ; -1.1  ];        [ 0.85 ; -1.525];        [ 1.075; -1.725];        [ 1.3  ; -1.925];        [ 1.525; -2.075];        [ 1.75 ; -1.9  ];        [ 2.   ; -1.475];        [ 2.175; -1.05 ];        [ 2.225; -0.475];        [ 2.5  ;  0.175];        [ 2.4  ;  0.8  ];        [ 1.775;  1.425];        [ 1.125;  2.025];        [ 0.075;  2.2  ];        [-1.1  ;  2.1  ];        [-1.925;  2.1  ];        [-2.25 ;  2.05 ]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ewhich makes sense when glancing at the scatterplot of \u003ccode\u003ea\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003eNow; for speed; we take the length of the velocity vector. However; there\u0027s one thing that we haven\u0027t really kept in mind here: \u003cstrong\u003eeverything is a function of \u003ccode\u003et\u003c/code\u003e\u003c/strong\u003e. Thus; \u003ccode\u003eds/dt\u003c/code\u003e is really a scalar function of \u003ccode\u003et\u003c/code\u003e (as opposed to a vector function of \u003ccode\u003et\u003c/code\u003e); just like \u003ccode\u003edx/dt\u003c/code\u003e and \u003ccode\u003edy/dt\u003c/code\u003e. Thus; we will represent \u003ccode\u003eds_dt\u003c/code\u003e as a \u003ccode\u003enumpy\u003c/code\u003e array of values at each of the one second time intervals; each value corresponding to an approximation of the speed at each second:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eds_dt \u003d np.sqrt(dx_dt * dx_dt + dy_dt * dy_dt) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis yields the following array:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003earray([ 0.3       ;  0.62699681;  1.00623059;  1.36014705;  1.74588803;         2.03254766;  2.32284847;  2.57512136;  2.58311827;  2.48508048;         2.41518633;  2.27513736;  2.50611752;  2.52982213;  2.27623593;         2.31651678;  2.20127804;  2.37065392;  2.8487936 ;  3.04384625]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ewhich; again; makes some sense as you look at the gaps between the dots on the scatterplot of \u003ccode\u003ea\u003c/code\u003e: the object picks up speed; slowing down a bit as it takes the corner; and then speeds back up even more.\u003c/p\u003e  \u003cp\u003eNow; in order to find the unit tangent vector; we need to make a small transformation to \u003ccode\u003eds_dt\u003c/code\u003e so that its size is the same as that of \u003ccode\u003evelocity\u003c/code\u003e (this effectively allows us to divide the vector-valued function \u003ccode\u003evelocity\u003c/code\u003e by the (representation of) the scalar function \u003ccode\u003eds_dt\u003c/code\u003e):\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003etangent \u003d np.array([1/ds_dt] * 2).transpose() * velocity \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis yields the following \u003ccode\u003enumpy\u003c/code\u003e array:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003earray([[ 1.        ;  0.        ];        [ 0.99681528; -0.07974522];        [ 0.89442719; -0.4472136 ];        [ 0.5881717 ; -0.80873608];        [ 0.48685826; -0.87348099];        [ 0.52889289; -0.84868859];        [ 0.55965769; -0.82872388];        [ 0.5922051 ; -0.80578727];        [ 0.67747575; -0.73554511];        [ 0.80480291; -0.59354215];        [ 0.90055164; -0.43474907];        [ 0.97796293; -0.2087786 ];        [ 0.99755897;  0.06982913];        [ 0.9486833 ;  0.31622777];        [ 0.77979614;  0.62603352];        [ 0.48564293;  0.87415728];        [ 0.03407112;  0.99941941];        [-0.46400699;  0.88583154];        [-0.67572463;  0.73715414];        [-0.73919634;  0.67349   ]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eNote two things: 1. At each value of \u003ccode\u003et\u003c/code\u003e; \u003ccode\u003etangent\u003c/code\u003e is pointing in the same direction as \u003ccode\u003evelocity\u003c/code\u003e; and 2. At each value of \u003ccode\u003et\u003c/code\u003e; \u003ccode\u003etangent\u003c/code\u003e is a unit vector. Indeed:\u003c/p\u003e  \u003cp\u003eIn [12]:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [12]: np.sqrt(tangent[:;0] * tangent[:;0] + tangent[:;1] * tangent[:;1]) Out[12]: array([ 1.;  1.;  1.;  1.;  1.;  1.;  1.;  1.;  1.;  1.;  1.;  1.;  1.;         1.;  1.;  1.;  1.;  1.;  1.;  1.]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eNow; since we take the derivative of the tangent vector and divide by its length to get the unit normal vector; we do the same trick (isolating the components of \u003ccode\u003etangent\u003c/code\u003e for convenience):\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003etangent_x \u003d tangent[:; 0] tangent_y \u003d tangent[:; 1]  deriv_tangent_x \u003d np.gradient(tangent_x) deriv_tangent_y \u003d np.gradient(tangent_y)  dT_dt \u003d np.array([ [deriv_tangent_x[i]; deriv_tangent_y[i]] for i in range(deriv_tangent_x.size)])  length_dT_dt \u003d np.sqrt(deriv_tangent_x * deriv_tangent_x + deriv_tangent_y * deriv_tangent_y)  normal \u003d np.array([1/length_dT_dt] * 2).transpose() * dT_dt \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis gives us the following vector for \u003ccode\u003enormal\u003c/code\u003e:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003earray([[-0.03990439; -0.9992035 ];        [-0.22975292; -0.97324899];        [-0.48897562; -0.87229745];        [-0.69107645; -0.72278167];        [-0.8292422 ; -0.55888941];        [ 0.85188045;  0.52373629];        [ 0.8278434 ;  0.56095927];        [ 0.78434982;  0.62031876];        [ 0.70769355;  0.70651953];        [ 0.59568265;  0.80321988];        [ 0.41039706;  0.91190693];        [ 0.18879684;  0.98201617];        [-0.05568352;  0.99844847];        [-0.36457012;  0.93117594];        [-0.63863584;  0.76950911];        [-0.89417603;  0.44771557];        [-0.99992445;  0.0122923 ];        [-0.93801622; -0.34659137];        [-0.79170904; -0.61089835];        [-0.70603568; -0.70817626]]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eNote that the normal vector represents the direction in which the curve is turning. The vector above then makes sense when viewed in conjunction with the scatterplot for \u003ccode\u003ea\u003c/code\u003e. In particular; we go from turning down to turning up after the fifth point; and we start turning to the left (with respect to the x axis) after the 12th point.\u003c/p\u003e  \u003cp\u003eFinally; to get the tangential and normal components of acceleration; we need the second derivatives of \u003ccode\u003es\u003c/code\u003e; \u003ccode\u003ex\u003c/code\u003e; and \u003ccode\u003ey\u003c/code\u003e with respect to \u003ccode\u003et\u003c/code\u003e; and then we can get the curvature and the rest of our components (keeping in mind that they are all scalar functions of \u003ccode\u003et\u003c/code\u003e):\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ed2s_dt2 \u003d np.gradient(ds_dt) d2x_dt2 \u003d np.gradient(dx_dt) d2y_dt2 \u003d np.gradient(dy_dt)  curvature \u003d np.abs(d2x_dt2 * dy_dt - dx_dt * d2y_dt2) / (dx_dt * dx_dt + dy_dt * dy_dt)**1.5 t_component \u003d np.array([d2s_dt2] * 2).transpose() n_component \u003d np.array([curvature * ds_dt * ds_dt] * 2).transpose()  acceleration \u003d t_component * tangent + n_component * normal \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28439701",  "f0_": "How to save and load numpy.array() data properly?",  "f1_": "python|arrays|numpy",  "answer_count": "4",  "question_scoer": "133",  "questions_creation_date": "2015-02-10T19:02:18.577Z",  "answers_score": "198",  "answers_creation_date": "2015-02-10T19:31:45.433Z",  "questions_body": "\u003cp\u003eI wonder; how to save and load \u003ccode\u003enumpy.array\u003c/code\u003e data properly. Currently I\u0027m using the \u003ccode\u003enumpy.savetxt()\u003c/code\u003e method. For example; if I got an array \u003ccode\u003emarkers\u003c/code\u003e; which looks like this:\u003c/p\u003e  \u003cp\u003e\u003cimg src\u003d\"https://i.stack.imgur.com/gpbT1.png\" alt\u003d\"enter image description here\"\u003e\u003c/p\u003e  \u003cp\u003eI try to save it by the use of:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enumpy.savetxt(\u0027markers.txt\u0027; markers) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIn other script I try to open previously saved file:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003emarkers \u003d np.fromfile(\"markers.txt\") \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eAnd that\u0027s what I get...\u003c/p\u003e  \u003cp\u003e\u003cimg src\u003d\"https://i.stack.imgur.com/bO0CB.png\" alt\u003d\"enter image description here\"\u003e\u003c/p\u003e  \u003cp\u003eSaved data first looks like this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 0.000000000000000000e+00 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eBut when I save just loaded data by the use of the same method; ie. \u003ccode\u003enumpy.savetxt()\u003c/code\u003e it looks like this:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e1.398043286095131769e-76 1.398043286095288860e-76 1.396426376485745879e-76 1.398043286055061908e-76 1.398043286095288860e-76 1.182950697433698368e-76 1.398043275797188953e-76 1.398043286095288860e-76 1.210894289234927752e-99 1.398040649781712473e-76 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eWhat am I doing wrong? PS there are no other \"backstage\" operation which I perform. Just saving and loading; and that\u0027s what I get. Thank you in advance.\u003c/p\u003e",  "answers_body": "\u003cp\u003eThe most reliable way I have found to do this is to use \u003ccode\u003enp.savetxt\u003c/code\u003e with \u003ccode\u003enp.loadtxt\u003c/code\u003e and not \u003ccode\u003enp.fromfile\u003c/code\u003e which is better suited to binary files written with \u003ccode\u003etofile\u003c/code\u003e. The \u003ccode\u003enp.fromfile\u003c/code\u003e and \u003ccode\u003enp.tofile\u003c/code\u003e methods write and read binary files whereas \u003ccode\u003enp.savetxt\u003c/code\u003e writes a text file. So; for example:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003ea \u003d np.array([1; 2; 3; 4]) np.savetxt(\u0027test1.txt\u0027; a; fmt\u003d\u0027%d\u0027) b \u003d np.loadtxt(\u0027test1.txt\u0027; dtype\u003dint) a \u003d\u003d b # array([ True;  True;  True;  True]; dtype\u003dbool) \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eOr:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003ea.tofile(\u0027test2.dat\u0027) c \u003d np.fromfile(\u0027test2.dat\u0027; dtype\u003dint) c \u003d\u003d a # array([ True;  True;  True;  True]; dtype\u003dbool) \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eI use the former method even if it is slower and creates bigger files (sometimes): the binary format can be platform dependent (for example; the file format depends on the endianness of your system).\u003c/p\u003e \u003cp\u003eThere is a \u003cem\u003eplatform independent\u003c/em\u003e format for NumPy arrays; which can be saved and read with \u003ccode\u003enp.save\u003c/code\u003e and \u003ccode\u003enp.load\u003c/code\u003e:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003enp.save(\u0027test3.npy\u0027; a)    # .npy extension is added if not given d \u003d np.load(\u0027test3.npy\u0027) a \u003d\u003d d # array([ True;  True;  True;  True]; dtype\u003dbool) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "28617841",  "f0_": "Rounding to nearest int with numpy.rint() not consistent for .5",  "f1_": "python|numpy",  "answer_count": "8",  "question_scoer": "30",  "questions_creation_date": "2015-02-19T22:01:16.323Z",  "answers_score": "12",  "answers_creation_date": "2015-02-19T22:05:48.163Z",  "questions_body": "\u003cp\u003e\u003ca href\u003d\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.rint.html\" rel\u003d\"noreferrer\"\u003enumpy\u0027s round int\u003c/a\u003e doesn\u0027t seem to be consistent with how it deals with xxx.5 \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [2]: np.rint(1.5) Out[2]: 2.0  In [3]: np.rint(10.5) Out[3]: 10.0 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003e1.5 is rounded up while 10.5 is rounded down. Is there a reason for this? Is it just and artifact of \u003ca href\u003d\"https://stackoverflow.com/questions/21895756/why-are-floating-point-numbers-inaccurate\"\u003ethe inaccuracy of floats\u003c/a\u003e?\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003eEdit\u003c/strong\u003e\u003c/p\u003e  \u003cp\u003eIs there a way to get the desired functionality where n.5 is rounded up i.e. to n+1 for both n \u003d even or odd?\u003c/p\u003e",  "answers_body": "\u003cp\u003eSo; this kind of behavior (as noted in comments); is a very traditional form of rounding; seen in the \u003ca href\u003d\"http://en.wikipedia.org/wiki/Rounding#Round_half_to_even\" rel\u003d\"noreferrer\"\u003eround half to even\u003c/a\u003e method. Also known (according to David Heffernan) as banker\u0027s rounding. The \u003ccode\u003enumpy\u003c/code\u003e documentation around this behavior implies that they are using this type of rounding; but also implies that there may be issues with the way in which \u003ccode\u003enumpy\u003c/code\u003e interacts with the IEEE floating point format. (shown below)\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eNotes ----- For values exactly halfway between rounded decimal values; Numpy rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0; -0.5 and 0.5 round to 0.0; etc. Results may also be surprising due to the inexact representation of decimal fractions in the IEEE floating point standard [1]_ and errors introduced when scaling by powers of ten. \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eWhether or not that is the case; I honestly don\u0027t know. I do know that large portions of the \u003ccode\u003enumpy\u003c/code\u003e core are still written in FORTRAN 77; which predates the IEEE standard (set in 1984); but I don\u0027t know enough FORTRAN 77 to say whether or not there\u0027s some issue with the interface here.\u003c/p\u003e  \u003cp\u003eIf you\u0027re looking to just round up regardless; the \u003ccode\u003enp.ceil\u003c/code\u003e function (ceiling function in general); will do this. If you\u0027re looking for the opposite (always rounding down); the \u003ccode\u003enp.floor\u003c/code\u003e function will achieve this.\u003c/p\u003e"}
{  "id": "31305889",  "f0_": "Reshaping numpy array without using two for loops",  "f1_": "python|arrays|numpy",  "answer_count": "5",  "question_scoer": "-4",  "questions_creation_date": "2015-07-08T23:59:53.920Z",  "answers_score": "0",  "answers_creation_date": "2015-07-09T04:29:15.270Z",  "questions_body": "\u003cp\u003eI have two numpy arrays\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np x \u003d np.linspace(1e10; 1e12; num\u003d50) # 50 values y \u003d np.linspace(1e5; 1e7; num\u003d50)   # 50 values x.shape # output is (50;) y.shape # output is (50;) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI would like to create a function which returns an array shaped \u003ccode\u003e(50;50)\u003c/code\u003e such that the first x value \u003ccode\u003ex0\u003c/code\u003e is evaluated for all y values; etc. \u003c/p\u003e  \u003cp\u003eThe current function I am using is fairly complicated; so let\u0027s use an easier example. Let\u0027s say the function is\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef func(x;y):     return x**2 + y**2 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow do I shape this to be a \u003ccode\u003e(50;50)\u003c/code\u003e array? At the moment; it will output 50 values. Would you use a for loop inside an array? \u003c/p\u003e  \u003cp\u003eSomething like:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enp.array([[func(x;y) for i in x] for j in y) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut without using two for loops. This takes forever to run.\u003c/p\u003e  \u003chr\u003e  \u003cp\u003eEDIT: It has been requested I share my \"complicated\" function. Here it goes:\u003c/p\u003e  \u003cp\u003eThere is a data vector which is a 1D numpy array of 4000 measurements. There is also a \"normalized_matrix\"; which is shaped (4000;4000)---it is nothing special; just a matrix with entry values  of integers between 0 and 1; e.g. 0.5567878. These are the two \"given\" inputs. \u003c/p\u003e  \u003cp\u003eMy function returns the matrix multiplication product of transpose(datavector) * matrix * datavector; which is a single value. \u003c/p\u003e  \u003cp\u003eNow; as you can see in the code; I have initialized two arrays; x and y; which pass through a series of \"x parameters\" and \"y parameters\". That is; what does \u003ccode\u003efunc(x;y)\u003c/code\u003e return for value \u003ccode\u003ex1\u003c/code\u003e and value \u003ccode\u003ey1\u003c/code\u003e; i.e. \u003ccode\u003efunc(x1;y1)\u003c/code\u003e? \u003c/p\u003e  \u003cp\u003eThe shape of \u003ccode\u003ematrix1\u003c/code\u003e is (50; 4000; 4000). The shape of \u003ccode\u003ematrix2\u003c/code\u003e is (50; 4000; 4000). Ditto for \u003ccode\u003etotal_matrix\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003e\u003ccode\u003enormalized_matrix\u003c/code\u003e is shape (4000;4000) and \u003ccode\u003eid_mat\u003c/code\u003e is shaped (4000;4000).  \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enormalized_matrix print normalized_matrix.shape #output (4000;4000)  data_vector \u003d datarr print datarr.shape #output (4000;)  def func(x; y):     matrix1 \u003d x [:; None; None] * normalized_matrix[None; :; :]     matrix2 \u003d y[:; None; None] * id_mat[None; :; :]     total_matrix \u003d matrix1 + matrix2     # transpose(datavector) * matrix * datavector     # by matrix multiplication; equals single value     return  np.array([ np.dot(datarr.T;  np.dot(total_matrix; datarr) )  ]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIf I try to use \u003ccode\u003enp.meshgrid()\u003c/code\u003e; that is; if I try\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ex \u003d np.linspace(1e10; 1e12; num\u003d50) # 50 values y \u003d np.linspace(1e5; 1e7; num\u003d50)   # 50 values  X; Y \u003d np.meshgrid(x;y)  z \u003d func(X; Y) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI get the following value error: \u003ccode\u003eValueError: operands could not be broadcast together with shapes (50;1;1;50) (1;4000;4000)\u003c/code\u003e. \u003c/p\u003e",  "answers_body": "\u003cp\u003eI think there is a better way; it is right on the tip of my tongue; but as an interim measure:\u003c/p\u003e  \u003cp\u003eYou are operating on 1x2 windows of a meshgrid.  You can use \u003ccode\u003eas_strided\u003c/code\u003e from \u003ccode\u003enumpy.lib.stride_tricks\u003c/code\u003e to rearrange the \u003ccode\u003emeshgrid\u003c/code\u003e into two-element windows; then apply your function to the resultant array.  I like to use a generic nd solution; \u003ca href\u003d\"http://www.johnvinyard.com/blog/?p\u003d268\" rel\u003d\"nofollow noreferrer\"\u003e\u003ccode\u003esliding_windows\u003c/code\u003e\u003c/a\u003e (\u003ca href\u003d\"http://www.johnvinyard.com/blog/?p\u003d268\" rel\u003d\"nofollow noreferrer\"\u003ehttp://www.johnvinyard.com/blog/?p\u003d268\u003c/a\u003e) (Not mine) to transform the array.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np a \u003d np.array([1;2;3]) b \u003d np.array([.1; .2; .3]) z\u003d np.array(np.meshgrid(a;b)) def foo((x;y)):     return x+y  \u0026gt;\u0026gt;\u0026gt; z.shape (2; 3; 3) \u0026gt;\u0026gt;\u0026gt; t \u003d sliding_window(z; (2;1;1)) \u0026gt;\u0026gt;\u0026gt; t array([[ 1. ;  0.1];        [ 2. ;  0.1];        [ 3. ;  0.1];        [ 1. ;  0.2];        [ 2. ;  0.2];        [ 3. ;  0.2];        [ 1. ;  0.3];        [ 2. ;  0.3];        [ 3. ;  0.3]]) \u0026gt;\u0026gt;\u0026gt; v \u003d np.apply_along_axis(foo; 1; t) \u0026gt;\u0026gt;\u0026gt; v array([ 1.1;  2.1;  3.1;  1.2;  2.2;  3.2;  1.3;  2.3;  3.3]) \u0026gt;\u0026gt;\u0026gt; v.reshape((len(a); len(b))) array([[ 1.1;  2.1;  3.1];        [ 1.2;  2.2;  3.2];        [ 1.3;  2.3;  3.3]]) \u0026gt;\u0026gt;\u0026gt; \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eThis should be somewhat faster.\u003c/p\u003e  \u003cp\u003eYou may need to modify your function\u0027s \u003cem\u003eargument signature\u003c/em\u003e.\u003c/p\u003e  \u003cp\u003eIf the link to the \u003ccode\u003ejohnvinyard.com blog\u003c/code\u003e breaks; I\u0027ve posted the the \u003ccode\u003esliding_window\u003c/code\u003e implementation in other SO answers - \u003ca href\u003d\"https://stackoverflow.com/a/22749434/2823755\"\u003ehttps://stackoverflow.com/a/22749434/2823755\u003c/a\u003e\u003c/p\u003e  \u003cp\u003eSearch around and you\u0027ll find many other \u003cem\u003etricky\u003c/em\u003e \u003ccode\u003eas_strided\u003c/code\u003e solutions. \u003c/p\u003e"}
{  "id": "10335090",  "f0_": "Replace negative values in an numpy array",  "f1_": "python|numpy",  "answer_count": "6",  "question_scoer": "101",  "questions_creation_date": "2012-04-26T14:03:09.877Z",  "answers_score": "4",  "answers_creation_date": "2015-07-10T14:20:57.350Z",  "questions_body": "\u003cp\u003eIs there a simple way of replacing all negative values in an array with 0?\u003c/p\u003e \u003cp\u003eI\u0027m having a complete block on how to do it using a NumPy array.\u003c/p\u003e \u003cp\u003eE.g.\u003c/p\u003e \u003cpre\u003e\u003ccode\u003ea \u003d array([1; 2; 3; -4; 5]) \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eI need to return\u003c/p\u003e \u003cpre\u003e\u003ccode\u003e[1; 2; 3; 0; 5] \u003c/code\u003e\u003c/pre\u003e \u003cp\u003e\u003ccode\u003ea \u0026lt; 0\u003c/code\u003e gives:\u003c/p\u003e \u003cpre\u003e\u003ccode\u003e[False; False; False; True; False] \u003c/code\u003e\u003c/pre\u003e \u003cp\u003eThis is where I\u0027m stuck - how to use this array to modify the original array.\u003c/p\u003e",  "answers_body": "\u003cp\u003eAnd yet another possibility:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eIn [2]: a \u003d array([1; 2; 3; -4; 5])  In [3]: where(a\u0026lt;0; 0; a) Out[3]: array([1; 2; 3; 0; 5]) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "27050108",  "f0_": "Convert numpy type to python",  "f1_": "python|json|numpy|pandas",  "answer_count": "6",  "question_scoer": "48",  "questions_creation_date": "2014-11-20T21:42:32.353Z",  "answers_score": "4",  "answers_creation_date": "2015-08-02T08:44:31.817Z",  "questions_body": "\u003cp\u003eI have a list of dicts in the following form that I generate from pandas. I want to convert it to a json format.\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003elist_val \u003d [{1.0: 685}; {2.0: 8}] output \u003d json.dumps(list_val) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHowever; json.dumps throws an error: TypeError: 685 is not JSON serializable\u003c/p\u003e  \u003cp\u003eI am guessing it\u0027s a type conversion issue from numpy to python(?).\u003c/p\u003e  \u003cp\u003eHowever; when I convert the values v of each dict in the array using np.int32(v) it still throws the error.\u003c/p\u003e  \u003cp\u003eEDIT: Here\u0027s the full code\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e            new \u003d df[df[label] \u003d\u003d label_new]              ks_dict \u003d json.loads(content)             ks_list \u003d ks_dict[\u0027variables\u0027]             freq_counts \u003d []              for ks_var in ks_list:                      freq_var \u003d dict()                     freq_var[\"name\"] \u003d ks_var[\"name\"]                     ks_series \u003d new[ks_var[\"name\"]]                     temp_df \u003d ks_series.value_counts().to_dict()                     freq_var[\"new\"] \u003d [{u: np.int32(v)} for (u; v) in temp_df.iteritems()]                                 freq_counts.append(freq_var)             out \u003d json.dumps(freq_counts) \u003c/code\u003e\u003c/pre\u003e",  "answers_body": "\u003cp\u003eYou could also convert the array to a python list (use the \u003ccode\u003etolist\u003c/code\u003e method) and then convert the list to json.\u003c/p\u003e"}
{  "id": "31256252",  "f0_": "Why does numpy.linalg.solve() offer more precise matrix inversions than numpy.linalg.inv()?",  "f1_": "python|arrays|numpy|matrix|linear-algebra",  "answer_count": "1",  "question_scoer": "36",  "questions_creation_date": "2015-07-06T21:49:02.503Z",  "answers_score": "52",  "answers_creation_date": "2015-07-07T00:31:31.657Z",  "questions_body": "\u003cp\u003eI do not quite understand why \u003ccode\u003enumpy.linalg.solve()\u003c/code\u003e gives the more precise answer; whereas \u003ccode\u003enumpy.linalg.inv()\u003c/code\u003e breaks down somewhat; giving (what I believe are) estimates. \u003c/p\u003e  \u003cp\u003eFor a concrete example; I am solving the equation \u003ccode\u003eC^{-1} * d\u003c/code\u003e  where \u003ccode\u003eC\u003c/code\u003e denotes a matrix; and \u003ccode\u003ed\u003c/code\u003e is a vector-array. For the sake of discussion; the dimensions of \u003ccode\u003eC\u003c/code\u003e are shape \u003ccode\u003e(1000;1000)\u003c/code\u003e and \u003ccode\u003ed\u003c/code\u003e is shape \u003ccode\u003e(1;1000)\u003c/code\u003e. \u003c/p\u003e  \u003cp\u003e\u003ccode\u003enumpy.linalg.solve(A; b)\u003c/code\u003e solves the equation \u003ccode\u003eA*x\u003db\u003c/code\u003e for x; i.e. \u003ccode\u003ex \u003d A^{-1} * b.\u003c/code\u003e Therefore; I could either solve this equation by\u003c/p\u003e  \u003cp\u003e(1)\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003einverse \u003d numpy.linalg.inv(C) result \u003d inverse * d \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eor (2)\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enumpy.linalg.solve(C; d) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eMethod (2) gives far more precise results. Why is this?  \u003c/p\u003e  \u003cp\u003eWhat exactly is happening such that one \"works better\" than the other? \u003c/p\u003e",  "answers_body": "\u003cp\u003e\u003ccode\u003enp.linalg.solve(A; b)\u003c/code\u003e does \u003cem\u003enot\u003c/em\u003e compute the inverse of \u003cem\u003eA\u003c/em\u003e. Instead it calls one of the \u003ca href\u003d\"http://www.netlib.org/lapack/double/dgesv.f\" rel\u003d\"noreferrer\"\u003e\u003ccode\u003egesv\u003c/code\u003e LAPACK routines\u003c/a\u003e; which first factorizes \u003cem\u003eA\u003c/em\u003e using LU decomposition; then solves for \u003cem\u003ex\u003c/em\u003e using forward and backward substitution (see \u003ca href\u003d\"https://en.wikipedia.org/wiki/LU_decomposition#Solving_linear_equations\" rel\u003d\"noreferrer\"\u003ehere\u003c/a\u003e).\u003c/p\u003e  \u003cp\u003e\u003ccode\u003enp.linalg.inv\u003c/code\u003e uses the same method to compute the inverse of \u003cem\u003eA\u003c/em\u003e by solving for \u003cem\u003eA\u003csup\u003e-1\u003c/sup\u003e\u003c/em\u003e in \u003cem\u003eA·A\u003csup\u003e-1\u003c/sup\u003e \u003d I\u003c/em\u003e where \u003cem\u003eI\u003c/em\u003e is the identity*. The factorization step is exactly the same as above; but it takes more floating point operations to solve for \u003cem\u003eA\u003csup\u003e-1\u003c/sup\u003e\u003c/em\u003e (an \u003cem\u003en×n\u003c/em\u003e matrix) than for \u003cem\u003ex\u003c/em\u003e (an \u003cem\u003en\u003c/em\u003e-long vector). Additionally; if you then wanted to obtain \u003cem\u003ex\u003c/em\u003e via the identity \u003cem\u003eA\u003csup\u003e-1\u003c/sup\u003e·b \u003d x\u003c/em\u003e then the extra matrix multiplication would incur yet more floating point operations; and therefore slower performance and more numerical error.\u003c/p\u003e  \u003cp\u003eThere\u0027s no need for the intermediate step of computing \u003cem\u003eA\u003csup\u003e-1\u003c/sup\u003e\u003c/em\u003e - it is  faster and more accurate to obtain \u003cem\u003ex\u003c/em\u003e directly.\u003c/p\u003e  \u003chr\u003e  \u003cp\u003e* The relevant bit of source for \u003ccode\u003einv\u003c/code\u003e is \u003ca href\u003d\"https://github.com/numpy/numpy/blob/master/numpy/linalg/umath_linalg.c.src#L1727-L1729\" rel\u003d\"noreferrer\"\u003ehere\u003c/a\u003e. Unfortunately it\u0027s a bit tricky to understand since it\u0027s templated C. The important thing to note is that an identity matrix is being passed to the LAPACK solver as parameter \u003ccode\u003eB\u003c/code\u003e.\u003c/p\u003e"}
{  "id": "31305889",  "f0_": "Reshaping numpy array without using two for loops",  "f1_": "python|arrays|numpy",  "answer_count": "5",  "question_scoer": "-4",  "questions_creation_date": "2015-07-08T23:59:53.920Z",  "answers_score": "-1",  "answers_creation_date": "2015-07-09T00:12:30.433Z",  "questions_body": "\u003cp\u003eI have two numpy arrays\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003eimport numpy as np x \u003d np.linspace(1e10; 1e12; num\u003d50) # 50 values y \u003d np.linspace(1e5; 1e7; num\u003d50)   # 50 values x.shape # output is (50;) y.shape # output is (50;) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI would like to create a function which returns an array shaped \u003ccode\u003e(50;50)\u003c/code\u003e such that the first x value \u003ccode\u003ex0\u003c/code\u003e is evaluated for all y values; etc. \u003c/p\u003e  \u003cp\u003eThe current function I am using is fairly complicated; so let\u0027s use an easier example. Let\u0027s say the function is\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef func(x;y):     return x**2 + y**2 \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow do I shape this to be a \u003ccode\u003e(50;50)\u003c/code\u003e array? At the moment; it will output 50 values. Would you use a for loop inside an array? \u003c/p\u003e  \u003cp\u003eSomething like:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enp.array([[func(x;y) for i in x] for j in y) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003ebut without using two for loops. This takes forever to run.\u003c/p\u003e  \u003chr\u003e  \u003cp\u003eEDIT: It has been requested I share my \"complicated\" function. Here it goes:\u003c/p\u003e  \u003cp\u003eThere is a data vector which is a 1D numpy array of 4000 measurements. There is also a \"normalized_matrix\"; which is shaped (4000;4000)---it is nothing special; just a matrix with entry values  of integers between 0 and 1; e.g. 0.5567878. These are the two \"given\" inputs. \u003c/p\u003e  \u003cp\u003eMy function returns the matrix multiplication product of transpose(datavector) * matrix * datavector; which is a single value. \u003c/p\u003e  \u003cp\u003eNow; as you can see in the code; I have initialized two arrays; x and y; which pass through a series of \"x parameters\" and \"y parameters\". That is; what does \u003ccode\u003efunc(x;y)\u003c/code\u003e return for value \u003ccode\u003ex1\u003c/code\u003e and value \u003ccode\u003ey1\u003c/code\u003e; i.e. \u003ccode\u003efunc(x1;y1)\u003c/code\u003e? \u003c/p\u003e  \u003cp\u003eThe shape of \u003ccode\u003ematrix1\u003c/code\u003e is (50; 4000; 4000). The shape of \u003ccode\u003ematrix2\u003c/code\u003e is (50; 4000; 4000). Ditto for \u003ccode\u003etotal_matrix\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003e\u003ccode\u003enormalized_matrix\u003c/code\u003e is shape (4000;4000) and \u003ccode\u003eid_mat\u003c/code\u003e is shaped (4000;4000).  \u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enormalized_matrix print normalized_matrix.shape #output (4000;4000)  data_vector \u003d datarr print datarr.shape #output (4000;)  def func(x; y):     matrix1 \u003d x [:; None; None] * normalized_matrix[None; :; :]     matrix2 \u003d y[:; None; None] * id_mat[None; :; :]     total_matrix \u003d matrix1 + matrix2     # transpose(datavector) * matrix * datavector     # by matrix multiplication; equals single value     return  np.array([ np.dot(datarr.T;  np.dot(total_matrix; datarr) )  ]) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eIf I try to use \u003ccode\u003enp.meshgrid()\u003c/code\u003e; that is; if I try\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003ex \u003d np.linspace(1e10; 1e12; num\u003d50) # 50 values y \u003d np.linspace(1e5; 1e7; num\u003d50)   # 50 values  X; Y \u003d np.meshgrid(x;y)  z \u003d func(X; Y) \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eI get the following value error: \u003ccode\u003eValueError: operands could not be broadcast together with shapes (50;1;1;50) (1;4000;4000)\u003c/code\u003e. \u003c/p\u003e",  "answers_body": "\u003cp\u003eYou\u0027re on the right track with your list comprehension; you just need to add in an extra level of iteration:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003enp.array([[func(i;j) for i in x] for j in y]) \u003c/code\u003e\u003c/pre\u003e"}
{  "id": "15637336",  "f0_": "numpy.unique with order preserved",  "f1_": "python|numpy",  "answer_count": "7",  "question_scoer": "59",  "questions_creation_date": "2013-03-26T12:41:00.153Z",  "answers_score": "1",  "answers_creation_date": "2015-07-10T13:40:45.160Z",  "questions_body": "\u003cpre\u003e\u003ccode\u003e[\u0027b\u0027;\u0027b\u0027;\u0027b\u0027;\u0027a\u0027;\u0027a\u0027;\u0027c\u0027;\u0027c\u0027] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003enumpy.unique gives\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e[\u0027a\u0027;\u0027b\u0027;\u0027c\u0027] \u003c/code\u003e\u003c/pre\u003e  \u003cp\u003eHow can I get the original order preserved\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003e[\u0027b\u0027;\u0027a\u0027;\u0027c\u0027] \u003c/code\u003e\u003c/pre\u003e  \u003chr\u003e  \u003cp\u003eGreat answers. Bonus question. Why do none of these methods work with this dataset? \u003ca href\u003d\"http://www.uploadmb.com/dw.php?id\u003d1364341573\" rel\u003d\"noreferrer\"\u003ehttp://www.uploadmb.com/dw.php?id\u003d1364341573\u003c/a\u003e Here\u0027s the question \u003ca href\u003d\"https://stackoverflow.com/questions/15649097/numpy-sort-wierd-behavior?lq\u003d1\"\u003enumpy sort wierd behavior\u003c/a\u003e\u003c/p\u003e",  "answers_body": "\u003cp\u003eIf you want to delete repeated entries; like the Unix tool \u003ccode\u003euniq\u003c/code\u003e; this is a solution:\u003c/p\u003e  \u003cpre\u003e\u003ccode\u003edef uniq(seq):   \"\"\"   Like Unix tool uniq. Removes repeated entries.   :param seq: numpy.array   :return: seq   \"\"\"   diffs \u003d np.ones_like(seq)   diffs[1:] \u003d seq[1:] - seq[:-1]   idx \u003d diffs.nonzero()   return seq[idx] \u003c/code\u003e\u003c/pre\u003e"}


""" Query 7  Answer:  """

46821
